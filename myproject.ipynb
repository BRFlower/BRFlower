{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# -*- encoding: utf-8 -*-\n# siemese.py\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nfrom torch.utils import data\nimport cv2\nimport json\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy\nfrom PIL import Image\nimport pandas as pd\nfrom ast import Add\nfrom logging import critical\nfrom multiprocessing import reduction\nfrom turtle import forward\n\n#from siamese_net import SiameseNetwork\n#from CustomDataset import CustomDataset\n","metadata":{"execution":{"iopub.status.busy":"2022-10-27T05:10:21.941822Z","iopub.execute_input":"2022-10-27T05:10:21.942176Z","iopub.status.idle":"2022-10-27T05:10:21.949172Z","shell.execute_reply.started":"2022-10-27T05:10:21.942147Z","shell.execute_reply":"2022-10-27T05:10:21.948198Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# 计算平均值，方差\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, path):\n        super(CustomDataset,self).__init__()\n        # path=\"E:/MyProject/\"\n        self.path0=\"../input/standard/standard/\"\n        self.path1=\"../input/train1/train1/\"\n        self.path2=\"../input/train2/train2/\"\n        self.index0=json.loads(open(\"../input/index-standard/index_standard.json\",'r',encoding='utf-8').read())\n        self.index1=json.loads(open(\"../input/index-train1/index_train1.json\",'r',encoding='utf-8').read())\n        self.index2=json.loads(open(\"../input/index-train2/index_train2.json\",'r',encoding='utf-8').read())\n        self.dframe0=pd.DataFrame(self.index0)\n#         self.len1=len(self.index1)//4\n        self.len1=0\n        self.len2=len(self.index2)*6\n    def __getitem__(self,index):\n        if (index<self.len1):\n            word=self.index1[index][\"word\"]\n            filename1=self.path1+self.index1[index][\"filename\"]\n            score=self.index1[index][\"score\"]\n        else:\n            index-=self.len1\n            if (index<len(self.index2)*6):\n                word=self.index2[index//6][\"word\"]\n                filename1=self.path2+self.index1[index//6][\"filename\"]\n                score=self.index2[index//6][\"score\"]\n        item = self.dframe0.loc[self.dframe0['word']==word]\n        fileName = item[\"filename\"].values[0]\n        filename2 = self.path0 + fileName\n        #filename2=self.path0+self.dframe0.loc[self.dframe0[\"word\"]==word][\"filename\"][1]\n        \n        input_one = Image.open(filename2)\n        input_one_np = numpy.array(input_one)\n        input_one=numpy.where(numpy.sum(input_one_np,axis=2)==3*255,0,1)\n        # print(input_one.shape)\n\n        input_two = Image.open(filename1)\n        input_two_np = numpy.array(input_two)\n        input_two=numpy.where(input_two_np==255,0,1)\n        # print(input_two.shape)\n        \n        \n        input_one_tensor = torch.tensor(input_one, dtype=torch.float32).unsqueeze(0)\n        input_two_tensor = torch.tensor(input_two, dtype=torch.float32).unsqueeze(0)\n        label_tensor = torch.tensor(int(score),dtype=torch.float32)\n        # input_one.cuda()\n        # input_two.cuda()\n        # label.cuda()\n        input_one_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_one_tensor)\n        input_two_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_two_tensor)\n        return input_one_tensor,input_two_tensor, label_tensor\n\n    def __len__(self):\n#         len_1=len(self.index1)//4\n#         len_1=0\n#         len_2=len(self.index2)*6\n        return self.len1+self.len2\n\ndataset = CustomDataset(path=\"E:/MyProject/\")\nl=len(dataset)\ncal1=torch.tensor(0)\ncal2=torch.tensor(0)\nfor i in range(l):\n    a,b,c=dataset.__getitem__(i)\n    cal1=cal1+c\naverage=cal1/l\nfor i in range(l):\n    a,b,c=dataset.__getitem__(i)\n    cal2=cal2+(c-average)*(c-average)\ncal2=cal2/l\ncal2=torch.sqrt(cal2)\nprint(average,cal2)","metadata":{"_uuid":"c9b93d6c-1c2e-4b24-be5c-52e07b4952b9","_cell_guid":"f1e51bb1-f642-4050-a1d4-d5d7f8c029a3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# all\naverage=torch.tensor(80.6786)\nvariance=torch.tensor(9.0062)\nclass SiameseNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.cnn1 = nn.Sequential(\n            nn.BatchNorm2d(1,affine=True), # B*C*H*W\n            nn.Conv2d(1, 64, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 64 * 32 * 32\n        )\n        self.cnn2 = nn.Sequential(\n            nn.BatchNorm2d(64,affine=True), # B*C*H*W\n            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            # nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            # nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 128 * 16 * 16\n        )\n        self.cnn3 = nn.Sequential(\n            nn.BatchNorm2d(128,affine=True), # B*C*H*W\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            # nn.ReLU(inplace=True),\n            # nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 256 * 8 * 8\n        )\n        self.cnn4 = nn.Sequential(\n            nn.BatchNorm2d(256,affine=True), # B*C*H*W\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2),\n            # B * 512 * 4 * 4\n        )\n\n        self.fc1 = nn.Sequential(\n            nn.Linear(512 * 4 * 4, 100, bias=True),\n#             nn.Linear(1000, 100, bias=True),\n            # nn.ReLU(inplace=True),\n            # nn.Linear(20, 1)\n        )\n\n        self.fc2 = nn.Sequential(\n            nn.Linear(100, 20),\n            nn.ReLu(inplace=True),\n            nn.Linear(20,1),\n        )\n        # for m in self.modules():\n        #     if isinstance(m,nn.Conv2d):\n        #         nn.init.kaiming_normal_(m.weight.data,0.3)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0.3)\n        #     elif isinstance(m,nn.Linear):\n        #         nn.init.kaiming_normal_(m.weight.data)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0.5)\n        #     elif isinstance(m,nn.BatchNorm2d):\n        #         nn.init.kaiming_normal_(m.weight.data,0.3)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0)\n    def forward_once(self, x):\n        B, C, H, W = x.shape\n        output = self.cnn1(x)\n        output = self.cnn2(output)\n        output = self.cnn3(output)\n        output = self.cnn4(output)\n        output = output.view(B, 512*4*4)\n        output = self.fc1(output)\n#         output = output.view(B,100)\n#         output = nn.BatchNorm1d(100,eps=1e-4,affine=True).cuda()(output) # B*C*H*W\n#         output = nn.Sigmoid()(output)\n        return output\n\n    def forward(self, input1, input2):\n        B, C, H, W = input1.shape\n        output1 = self.forward_once(input1)\n        # 7*20\n        output2 = self.forward_once(input2)\n#         output3 = nn.functional.cosine_similarity(output1, output2, dim=1)-torch.ones((1,B)).cuda()*0.995\n#         output3=torch.abs(output2-output1).sum(dim=1)\n#         output3=(output1-output2).norm(2,dim=1,keepdim=True)\n        output3=torch.abs(output1-output2)\n        output3=self.fc2(output3)\n#         output3 = output3.resize(B, 1)\n        output4=output3\n        output4=output4*variance+average\n        output4=torch.min(output4,torch.ones(B,1).cuda()*100)\n        return output4\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, path):\n        super(CustomDataset,self).__init__()\n        # path=\"E:/MyProject/\"\n        self.path0=\"../input/standard/standard/\"\n        self.path1=\"../input/train1/train1/\"\n        self.path2=\"../input/train2/train2/\"\n        self.index0=json.loads(open(\"../input/index-standard/index_standard.json\",'r',encoding='utf-8').read())\n        self.index1=json.loads(open(\"../input/index-train1/index_train1.json\",'r',encoding='utf-8').read())\n        self.index2=json.loads(open(\"../input/index-train2/index_train2.json\",'r',encoding='utf-8').read())\n        self.dframe0=pd.DataFrame(self.index0)\n#         self.len1=len(self.index1)//4\n        self.len1=0\n        self.len2=len(self.index2)*6\n    def __getitem__(self,index):\n        if (index<self.len1):\n            word=self.index1[index][\"word\"]\n            filename1=self.path1+self.index1[index][\"filename\"]\n            score=self.index1[index][\"score\"]\n        else:\n            index-=self.len1\n            if (index<len(self.index2)*6):\n                word=self.index2[index//6][\"word\"]\n                filename1=self.path2+self.index1[index//6][\"filename\"]\n                score=self.index2[index//6][\"score\"]\n        item = self.dframe0.loc[self.dframe0['word']==word]\n        fileName = item[\"filename\"].values[0]\n        filename2 = self.path0 + fileName\n        #filename2=self.path0+self.dframe0.loc[self.dframe0[\"word\"]==word][\"filename\"][1]\n        \n        input_one = Image.open(filename2)\n        input_one_np = numpy.array(input_one)\n        input_one=numpy.where(numpy.sum(input_one_np,axis=2)==3*255,0,1)\n        # print(input_one.shape)\n\n        input_two = Image.open(filename1)\n        input_two_np = numpy.array(input_two)\n        input_two=numpy.where(input_two_np==255,0,1)\n        # print(input_two.shape)\n        \n        \n        input_one_tensor = torch.tensor(input_one, dtype=torch.float32).unsqueeze(0)\n        input_two_tensor = torch.tensor(input_two, dtype=torch.float32).unsqueeze(0)\n        label_tensor = torch.tensor(int(score),dtype=torch.float32)\n        # input_one.cuda()\n        # input_two.cuda()\n        # label.cuda()\n        input_one_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_one_tensor)\n        input_two_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_two_tensor)\n        return input_one_tensor,input_two_tensor, label_tensor\n\n    def __len__(self):\n#         len_1=len(self.index1)//4\n#         len_1=0\n#         len_2=len(self.index2)*6\n        return self.len1+self.len2\n\n# train.py\ndataset = CustomDataset(path=\"E:/MyProject/\")\nprint(len(dataset))\n#train_dataset,test_dataset=data.random_split(dataset,torch(len(dataset)/100*95),len(dataset)-torch.floor(len(dataset)/100*95))\nn_train = int(len(dataset)/100*95)\nn_val = len(dataset) - n_train\ntrain_dataset,test_dataset=data.random_split(dataset,[n_train, n_val])\nprint(len(train_dataset))\nprint(len(test_dataset))\ntrain_dataloader=data.DataLoader(\n    train_dataset,\n    batch_size=64,    \n    shuffle=True,\n    #num_worders=8,\n    pin_memory=True,\n    drop_last=True\n)\ntest_dataloader=data.DataLoader(\n    test_dataset,\n    batch_size=1,\n    #num_worders=8,\n    shuffle=True,\n    pin_memory=True\n)\n\n\n# net\n\nsiamese=torch.load(\"./model.pth\")\n# siamese=SiameseNetwork()\nsiamese=siamese.cuda()\n#siamese =SiameseNetwork().cuda() #定义模型以致GPU\n\n# loss\n# loss_func = ContrastiveLoss() #定义损失函数\nloss_func = torch.nn.MSELoss()\n\n\naverage=torch.tensor(83.0401)\nvariance=torch.tensor(10.2655)\n\ntrain_list=[siamese.cnn1,siamese.cnn2,siamese.cnn3,siamese.fc1,siamese.fc2]\ndef train(a,b):\n    params=[\n        {\"params\":siamese.cnn1.parameters(),\"lr\":a},\n        {\"params\":siamese.cnn2.parameters(),\"lr\":a},\n        {\"params\":siamese.cnn3.parameters(),\"lr\":a},\n        {\"params\":siamese.cnn4.parameters(),\"lr\":a},\n        {\"params\":siamese.fc1.parameters(),\"lr\":b},\n        {\"params\":siamese.fc2.parameters(),\"lr\":b},\n    ]\n    optimizer=torch.optim.Adam(params) # Adam对学习率不太敏感\n    lost_sum=0\n    for i, (image1,image2,labels) in enumerate(train_dataloader): # enumerate 将一个可遍历的数据对象组合为一个索引序列\n        image1=image1.cuda()\n        image2=image2.cuda()\n        \n        labels=labels.cuda()\n#         print(image1.shape)\n#         print(image2.shape)\n        \n        # print(image1.shape, image2.shape)\n        optimizer.zero_grad()\n        outputs=siamese(image1,image2)\n        # print(outputs.shape, labels.shape)\n        loss=loss_func(outputs,labels)\n        lost_sum=lost_sum+((outputs-labels)*(outputs-labels)).sum()\n        loss.backward()\n        optimizer.step()\n#         print(\"epoch is {}, ite is {}/{}, loss is {}\".format(epoch+1, i, len(train_dataset) // 64, loss.item()))\n    torch.save(siamese,\"./model.pth\")\n    lost_sum=lost_sum/len(train_dataset)\n    print(lost_sum.sqrt())\n# training\n\nfor epoch in range(10): #epoch one usage of whole dataset\n    train(1e-4,1e-4)\n    train(1e-4,0)\n    train(0,1e-4)\n        \n    loss_test=0\n    lst=[]\n    for i,(image1,image2,labels) in enumerate(test_dataloader):\n        image1=image1.cuda()\n        image2=image2.cuda()\n        outputs=siamese(image1,image2)\n        outputs=outputs.cpu()\n        labels=labels.to(torch.float32)\n        #[batchsize]\n        #outputs=batchsize*cls_num\n        now=(outputs-labels)*(outputs-labels)\n        lst.append(outputs)\n        loss_test += now\n        if (i % 40 ==0):\n            print(outputs,labels)\n        # _, pred=outputs.max(dim=1)\n    loss_test=torch.sqrt(loss_test/len(test_dataloader))\n    print(\"epoch is {}, loss test is {}\".format(epoch+1,loss_test.item()))\n    \n    lst=torch.tensor(lst)\n    print(\"mean={},std={}\".format(torch.mean(lst),torch.std(lst)))\n    # input(\"next\")\n\ntorch.save(siamese,\"./model.pth\")\n\n# eval/test\n# save\n\n# load\n# inference","metadata":{"execution":{"iopub.status.busy":"2022-10-27T05:10:27.321390Z","iopub.execute_input":"2022-10-27T05:10:27.322054Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"7038\n6686\n352\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n","output_type":"stream"},{"name":"stdout","text":"tensor(71.8656, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(71.8626, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(71.7777, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[78.4981]], grad_fn=<ToCopyBackward0>) tensor([64.])\ntensor([[81.3802]], grad_fn=<ToCopyBackward0>) tensor([72.])\ntensor([[79.1115]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[81.7710]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[79.5328]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[81.1322]], grad_fn=<ToCopyBackward0>) tensor([66.])\ntensor([[78.3133]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[81.4211]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[79.4011]], grad_fn=<ToCopyBackward0>) tensor([81.])\nepoch is 1, loss test is 9.137033462524414\nmean=80.31226348876953,std=1.641648769378662\ntensor(71.8696, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(71.7895, device='cuda:0', grad_fn=<SqrtBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"average=torch.tensor(83.0401)\nvariance=torch.tensor(10.2655)\nclass SiameseNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.cnn1 = nn.Sequential(\n            nn.BatchNorm2d(1,affine=True), # B*C*H*W\n            nn.Conv2d(1, 64, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 64 * 32 * 32\n        )\n        self.cnn2 = nn.Sequential(\n            nn.BatchNorm2d(64,affine=True), # B*C*H*W\n            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            # nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            # nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 128 * 16 * 16\n        )\n        self.cnn3 = nn.Sequential(\n            nn.BatchNorm2d(128,affine=True), # B*C*H*W\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            # nn.ReLU(inplace=True),\n            # nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 256 * 8 * 8\n        )\n        self.cnn4 = nn.Sequential(\n            nn.BatchNorm2d(256,affine=True), # B*C*H*W\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 512 * 4 * 4\n        )\n\n        self.fc1 = nn.Sequential(\n            nn.Linear(512 * 4 * 4, 100, bias=True),\n#             nn.Linear(1000, 100, bias=True),\n            # nn.ReLU(inplace=True),\n            # nn.Linear(20, 1)\n        )\n\n        self.fc2 = nn.Sequential(\n            nn.Linear(100, 1, bias=False),\n        )\n        # for m in self.modules():\n        #     if isinstance(m,nn.Conv2d):\n        #         nn.init.kaiming_normal_(m.weight.data,0.3)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0.3)\n        #     elif isinstance(m,nn.Linear):\n        #         nn.init.kaiming_normal_(m.weight.data)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0.5)\n        #     elif isinstance(m,nn.BatchNorm2d):\n        #         nn.init.kaiming_normal_(m.weight.data,0.3)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0)\n    def forward_once(self, x):\n        B, C, H, W = x.shape\n        output = self.cnn1(x)\n        output = self.cnn2(output)\n        output = self.cnn3(output)\n        output = self.cnn4(output)\n        output = output.view(B, 512*4*4)\n        output = self.fc1(output)\n#         output = output.view(B,100)\n#         output = nn.BatchNorm1d(100,eps=1e-4,affine=True).cuda()(output) # B*C*H*W\n#         output = nn.Sigmoid()(output)\n        return output\n\n    def forward(self, input1, input2):\n        B, C, H, W = input1.shape\n        output1 = self.forward_once(input1)\n        # 7*20\n        output2 = self.forward_once(input2)\n#         output3 = nn.functional.cosine_similarity(output1, output2, dim=1)-torch.ones((1,B)).cuda()*0.995\n#         output3=torch.abs(output2-output1).sum(dim=1)\n#         output3=(output1-output2).norm(2,dim=1,keepdim=True)\n        output3=output1-output2\n        output3=self.fc2(output3)\n#         output3 = output3.resize(B, 1)\n        output4=output3\n        output4=output4*variance+average\n        return output4\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, path):\n        super(CustomDataset,self).__init__()\n        # path=\"E:/MyProject/\"\n        self.path0=\"../input/standard/standard/\"\n        self.path1=\"../input/train1/train1/\"\n        self.path2=\"../input/train2/train2/\"\n        self.index0=json.loads(open(\"../input/index-standard/index_standard.json\",'r',encoding='utf-8').read())\n        self.index1=json.loads(open(\"../input/index-train1/index_train1.json\",'r',encoding='utf-8').read())\n        self.index2=json.loads(open(\"../input/index-train2/index_train2.json\",'r',encoding='utf-8').read())\n        self.dframe0=pd.DataFrame(self.index0)\n#         self.len1=len(self.index1)//4\n        self.len1=0\n        self.len2=len(self.index2)*6\n    def __getitem__(self,index):\n        if (index<self.len1):\n            word=self.index1[index][\"word\"]\n            filename1=self.path1+self.index1[index][\"filename\"]\n            score=self.index1[index][\"score\"]\n        else:\n            index-=self.len1\n            if (index<len(self.index2)*6):\n                word=self.index2[index//6][\"word\"]\n                filename1=self.path2+self.index1[index//6][\"filename\"]\n                score=self.index2[index//6][\"score\"]\n        item = self.dframe0.loc[self.dframe0['word']==word]\n        fileName = item[\"filename\"].values[0]\n        filename2 = self.path0 + fileName\n        #filename2=self.path0+self.dframe0.loc[self.dframe0[\"word\"]==word][\"filename\"][1]\n        \n        input_one = Image.open(filename2)\n        input_one_np = numpy.array(input_one)\n        input_one=numpy.where(numpy.sum(input_one_np,axis=2)==3*255,0,1)\n        # print(input_one.shape)\n\n        input_two = Image.open(filename1)\n        input_two_np = numpy.array(input_two)\n        input_two=numpy.where(input_two_np==255,0,1)\n        # print(input_two.shape)\n        \n        \n        input_one_tensor = torch.tensor(input_one, dtype=torch.float32).unsqueeze(0)\n        input_two_tensor = torch.tensor(input_two, dtype=torch.float32).unsqueeze(0)\n        label_tensor = torch.tensor(int(score),dtype=torch.float32)\n        # input_one.cuda()\n        # input_two.cuda()\n        # label.cuda()\n        input_one_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_one_tensor)\n        input_two_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_two_tensor)\n        return input_one_tensor,input_two_tensor, label_tensor\n\n    def __len__(self):\n#         len_1=len(self.index1)//4\n#         len_1=0\n#         len_2=len(self.index2)*6\n        return self.len1+self.len2\n\ndataset = CustomDataset(path=\"E:/MyProject/\")\nprint(len(dataset))\ndataloader=data.DataLoader(\n    dataset,\n    batch_size=1,\n    #num_worders=8,\n    shuffle=True,\n    pin_memory=True\n)\n\n# net\n\nsiamese=torch.load(\"./model.pth\").cpu()\nprint (len(dataset))\naccuracy=0\nfor i,(image1,image2,labels) in enumerate(dataloader):\n    \n    outputs=siamese(image1,image2)\n    pred=outputs\n\n    labels=labels.cpu().numpy()[0]\n    pred=pred.cpu().detach().numpy()[0]\n    # batchsize*1*28*28\n    # 通道数（灰度图=1） 在显示时应放在最后\n\n    print(\"label\",labels)\n    print(\"pred\",pred)\n\naccuracy=torch.sqrt(accuracy/len(dataset))\n# 方差\nprint(\"accuracy is {}\".format(accuracy))\n      ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.copy(\"../input/myproject-model/model 5.pth\",\"./model.pth\")","metadata":{"execution":{"iopub.status.busy":"2022-10-27T05:10:03.174071Z","iopub.execute_input":"2022-10-27T05:10:03.174475Z","iopub.status.idle":"2022-10-27T05:10:03.706940Z","shell.execute_reply.started":"2022-10-27T05:10:03.174438Z","shell.execute_reply":"2022-10-27T05:10:03.705571Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'./model.pth'"},"metadata":{}}]},{"cell_type":"markdown","source":"运行顺序：shutil-1 -> import -> train/all -> shutil-2\n        shutil-1 -> import -> test -> shutil-2","metadata":{}}]}