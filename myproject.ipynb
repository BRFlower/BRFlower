{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# -*- encoding: utf-8 -*-\n# siemese.py\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nfrom torch.utils import data\nimport cv2\nimport json\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy\nfrom PIL import Image\nimport pandas as pd\nfrom ast import Add\nfrom logging import critical\nfrom multiprocessing import reduction\nfrom turtle import forward\n\n#from siamese_net import SiameseNetwork\n#from CustomDataset import CustomDataset\n","metadata":{"execution":{"iopub.status.busy":"2022-10-20T06:58:12.593829Z","iopub.execute_input":"2022-10-20T06:58:12.594202Z","iopub.status.idle":"2022-10-20T06:58:12.601063Z","shell.execute_reply.started":"2022-10-20T06:58:12.594169Z","shell.execute_reply":"2022-10-20T06:58:12.600090Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# 计算平均值，方差\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, path):\n        super(CustomDataset,self).__init__()\n        # path=\"E:/MyProject/\"\n        self.path0=\"../input/standard/standard/\"\n        self.path1=\"../input/train1/train1/\"\n        self.path2=\"../input/train2/train2/\"\n        self.index0=json.loads(open(\"../input/index-standard/index_standard.json\",'r',encoding='utf-8').read())\n        self.index1=json.loads(open(\"../input/index-train1/index_train1.json\",'r',encoding='utf-8').read())\n        self.index2=json.loads(open(\"../input/index-train2/index_train2.json\",'r',encoding='utf-8').read())\n        self.dframe0=pd.DataFrame(self.index0)\n\n    def __getitem__(self,index):\n        if (index<len(self.index1)//4):\n            word=self.index1[index][\"word\"]\n            filename1=self.path1+self.index1[index][\"filename\"]\n            score=self.index1[index][\"score\"]\n        else:\n            index-=len(self.index1)//4\n            if (index<len(self.index2)*6):\n                word=self.index2[index//6][\"word\"]\n                filename1=self.path2+self.index1[index//6][\"filename\"]\n                score=self.index2[index//6][\"score\"]\n        item = self.dframe0.loc[self.dframe0['word']==word]\n        fileName = item[\"filename\"].values[0]\n        filename2 = self.path0 + fileName\n        #filename2=self.path0+self.dframe0.loc[self.dframe0[\"word\"]==word][\"filename\"][1]\n        \n        input_one = Image.open(filename2)\n        input_one_np = numpy.array(input_one)\n        input_one=numpy.where(numpy.sum(input_one_np,axis=2)==3*255,0,1)\n        # print(input_one.shape)\n\n        input_two = Image.open(filename1)\n        input_two_np = numpy.array(input_two)\n        input_two=numpy.where(input_two_np==255,0,1)\n        # print(input_two.shape)\n        \n        \n        input_one_tensor = torch.tensor(input_one, dtype=torch.float32).unsqueeze(0)\n        input_two_tensor = torch.tensor(input_two, dtype=torch.float32).unsqueeze(0)\n        label_tensor = torch.tensor(int(score),dtype=torch.float32)\n        # input_one.cuda()\n        # input_two.cuda()\n        # label.cuda()\n        input_one_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_one_tensor)\n        input_two_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_two_tensor)\n        return input_one_tensor,input_two_tensor, label_tensor\n\n    def __len__(self):\n        len_1=len(self.index1)//4\n        len_2=len(self.index2)*6\n        return len_1+len_2\n\ndataset = CustomDataset(path=\"E:/MyProject/\")\nl=len(dataset)\ncal1=torch.tensor(0)\ncal2=torch.tensor(0)\nfor i in range(l):\n    a,b,c=dataset.__getitem__(i)\n    cal1=cal1+c\naverage=cal1/l\nfor i in range(l):\n    a,b,c=dataset.__getitem__(i)\n    cal2=cal2+(c-average)*(c-average)\ncal2=cal2/l\ncal2=torch.sqrt(cal2)\nprint(average,cal2)","metadata":{"_uuid":"c9b93d6c-1c2e-4b24-be5c-52e07b4952b9","_cell_guid":"f1e51bb1-f642-4050-a1d4-d5d7f8c029a3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-10-20T06:58:50.743067Z","iopub.execute_input":"2022-10-20T06:58:50.743479Z","iopub.status.idle":"2022-10-20T07:00:01.058055Z","shell.execute_reply.started":"2022-10-20T06:58:50.743449Z","shell.execute_reply":"2022-10-20T07:00:01.056954Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"tensor(83.0401) tensor(10.2655)\n","output_type":"stream"}]},{"cell_type":"code","source":"# all\naverage=torch.tensor(83.0401)\nvariance=torch.tensor(10.2655)\nclass SiameseNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.cnn1 = nn.Sequential(\n            nn.BatchNorm2d(1,affine=True), # B*C*H*W\n            nn.Conv2d(1, 64, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 64 * 32 * 32\n        )\n        self.cnn2 = nn.Sequential(\n            nn.BatchNorm2d(64,affine=True), # B*C*H*W\n            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            # nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            # nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 128 * 16 * 16\n        )\n        self.cnn3 = nn.Sequential(\n            nn.BatchNorm2d(128,affine=True), # B*C*H*W\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            # nn.ReLU(inplace=True),\n            # nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 256 * 8 * 8\n        )\n        self.cnn4 = nn.Sequential(\n            nn.BatchNorm2d(256,affine=True), # B*C*H*W\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 512 * 4 * 4\n        )\n\n        self.fc1 = nn.Sequential(\n            nn.Linear(512 * 4 * 4, 100, bias=True),\n#             nn.Linear(1000, 100, bias=True),\n            # nn.ReLU(inplace=True),\n            # nn.Linear(20, 1)\n        )\n\n        self.fc2 = nn.Sequential(\n            \n            nn.Linear(1, 4, bias=True),\n#             nn.ReLU(inplace=True),\n            nn.Linear(4, 1, bias=True),\n        )\n        # for m in self.modules():\n        #     if isinstance(m,nn.Conv2d):\n        #         nn.init.kaiming_normal_(m.weight.data,0.3)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0.3)\n        #     elif isinstance(m,nn.Linear):\n        #         nn.init.kaiming_normal_(m.weight.data)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0.5)\n        #     elif isinstance(m,nn.BatchNorm2d):\n        #         nn.init.kaiming_normal_(m.weight.data,0.3)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0)\n    def forward_once(self, x):\n        B, C, H, W = x.shape\n        output = self.cnn1(x)\n        output = self.cnn2(output)\n        output = self.cnn3(output)\n        output = self.cnn4(output)\n        output = output.view(B, 512*4*4)\n        output = self.fc1(output)\n#         output = output.view(B,100)\n#         output = nn.BatchNorm1d(100,eps=1e-4,affine=True).cuda()(output) # B*C*H*W\n#         output = nn.Sigmoid()(output)\n        return output\n\n    def forward(self, input1, input2):\n        B, C, H, W = input1.shape\n        output1 = self.forward_once(input1)\n        # 7*20\n        output2 = self.forward_once(input2)\n        output3 = nn.functional.cosine_similarity(output1, output2, dim=1)-torch.ones((1,B)).cuda()*0.995\n#         output3=torch.abs(output2-output1).sum(dim=1)\n        output3 = output3.resize(B, 1)\n        output4 = self.fc2(output3)\n#         output4=output3\n        output4=output4*variance+average\n        return output4\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, path):\n        super(CustomDataset,self).__init__()\n        # path=\"E:/MyProject/\"\n        self.path0=\"../input/standard/standard/\"\n        self.path1=\"../input/train1/train1/\"\n        self.path2=\"../input/train2/train2/\"\n        self.index0=json.loads(open(\"../input/index-standard/index_standard.json\",'r',encoding='utf-8').read())\n        self.index1=json.loads(open(\"../input/index-train1/index_train1.json\",'r',encoding='utf-8').read())\n        self.index2=json.loads(open(\"../input/index-train2/index_train2.json\",'r',encoding='utf-8').read())\n        self.dframe0=pd.DataFrame(self.index0)\n\n    def __getitem__(self,index):\n        if (index<len(self.index1)//4):\n            word=self.index1[index][\"word\"]\n            filename1=self.path1+self.index1[index][\"filename\"]\n            score=self.index1[index][\"score\"]\n        else:\n            index-=len(self.index1)//4\n            if (index<len(self.index2)*6):\n                word=self.index2[index//6][\"word\"]\n                filename1=self.path2+self.index1[index//6][\"filename\"]\n                score=self.index2[index//6][\"score\"]\n        item = self.dframe0.loc[self.dframe0['word']==word]\n        fileName = item[\"filename\"].values[0]\n        filename2 = self.path0 + fileName\n        #filename2=self.path0+self.dframe0.loc[self.dframe0[\"word\"]==word][\"filename\"][1]\n        \n        input_one = Image.open(filename2)\n        input_one_np = numpy.array(input_one)\n        input_one=numpy.where(numpy.sum(input_one_np,axis=2)==3*255,0,1)\n        # print(input_one.shape)\n\n        input_two = Image.open(filename1)\n        input_two_np = numpy.array(input_two)\n        input_two=numpy.where(input_two_np==255,0,1)\n        # print(input_two.shape)\n        \n        \n        input_one_tensor = torch.tensor(input_one, dtype=torch.float32).unsqueeze(0)\n        input_two_tensor = torch.tensor(input_two, dtype=torch.float32).unsqueeze(0)\n        label_tensor = torch.tensor(int(score),dtype=torch.float32)\n        # input_one.cuda()\n        # input_two.cuda()\n        # label.cuda()\n        input_one_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_one_tensor)\n        input_two_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_two_tensor)\n        return input_one_tensor,input_two_tensor, label_tensor\n\n    def __len__(self):\n        len_1=len(self.index1)//4\n        len_2=len(self.index2)*6\n        return len_1+len_2\n        # return len(images)-len(images)%64\n        # 整除batch_size\n\n    # @staticmethod\n    # def add(a,b):\n    #     return a+b\n# print(CustomDataset.add(1,2))\n\n# train.py\ndataset = CustomDataset(path=\"E:/MyProject/\")\nprint(len(dataset))\n#train_dataset,test_dataset=data.random_split(dataset,torch(len(dataset)/100*95),len(dataset)-torch.floor(len(dataset)/100*95))\nn_train = int(len(dataset)/100*95)\nn_val = len(dataset) - n_train\ntrain_dataset,test_dataset=data.random_split(dataset,[n_train, n_val])\nprint(len(train_dataset))\nprint(len(test_dataset))\ntrain_dataloader=data.DataLoader(\n    train_dataset,\n    batch_size=64,    \n    shuffle=True,\n    #num_worders=8,\n    pin_memory=True,\n    drop_last=True\n)\ntest_dataloader=data.DataLoader(\n    test_dataset,\n    batch_size=1,\n    #num_worders=8,\n    shuffle=True,\n    pin_memory=True\n)\n\n\n# net\n\n# siamese=torch.load(\"./model.pth\")\nsiamese=SiameseNetwork()\nsiamese=siamese.cuda()\n#siamese =SiameseNetwork().cuda() #定义模型以致GPU\n\n# loss\n# loss_func = ContrastiveLoss() #定义损失函数\nloss_func = torch.nn.MSELoss()\n\n\naverage=torch.tensor(83.0401)\nvariance=torch.tensor(10.2655)\n\ntrain_list=[siamese.cnn1,siamese.cnn2,siamese.cnn3,siamese.fc1,siamese.fc2]\ndef train(a,b):\n    params=[\n        {\"params\":siamese.cnn1.parameters(),\"lr\":a},\n        {\"params\":siamese.cnn2.parameters(),\"lr\":a},\n        {\"params\":siamese.cnn3.parameters(),\"lr\":a},\n        {\"params\":siamese.cnn4.parameters(),\"lr\":a},\n        {\"params\":siamese.fc1.parameters(),\"lr\":b},\n        {\"params\":siamese.fc2.parameters(),\"lr\":b},\n    ]\n    optimizer=torch.optim.Adam(params) # Adam对学习率不太敏感\n    for i, (image1,image2,labels) in enumerate(train_dataloader): # enumerate 将一个可遍历的数据对象组合为一个索引序列\n        image1=image1.cuda()\n        image2=image2.cuda()\n        \n        labels=labels.cuda()\n#         print(image1.shape)\n#         print(image2.shape)\n        \n        # print(image1.shape, image2.shape)\n        optimizer.zero_grad()\n        outputs=siamese(image1,image2)\n        # print(outputs.shape, labels.shape)\n        loss=loss_func(outputs,labels)\n        loss.backward()\n        optimizer.step()\n#         print(\"epoch is {}, ite is {}/{}, loss is {}\".format(epoch+1, i, len(train_dataset) // 64, loss.item()))\n    torch.save(siamese,\"./model.pth\")\n    \n# training\n\nfor epoch in range(5): #epoch one usage of whole dataset\n    train(1e-1,1e-3)\n    train(1e-1,0)\n    train(0,1e-3)\n        \n    loss_test=0\n    for i,(image1,image2,labels) in enumerate(test_dataloader):\n        image1=image1.cuda()\n        image2=image2.cuda()\n        outputs=siamese(image1,image2)\n        outputs=outputs.cpu()\n        labels=labels.to(torch.float32)\n        #[batchsize]\n        #outputs=batchsize*cls_num\n        now=(outputs-labels)*(outputs-labels)\n        loss_test += now\n        if (i % 10 ==0):\n            print(outputs,labels)\n        # _, pred=outputs.max(dim=1)\n\n    loss_test=torch.sqrt(loss_test/len(test_dataloader))\n    print(\"epoch is {}, loss test is {}\".format(epoch+1,loss_test.item()))\n    # input(\"next\")\n\ntorch.save(siamese,\"./model.pth\")\n\n# eval/test\n# save\n\n# load\n# inference","metadata":{"execution":{"iopub.status.busy":"2022-10-20T07:10:00.766372Z","iopub.execute_input":"2022-10-20T07:10:00.766730Z","iopub.status.idle":"2022-10-20T07:18:17.356731Z","shell.execute_reply.started":"2022-10-20T07:10:00.766699Z","shell.execute_reply":"2022-10-20T07:18:17.354338Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"8149\n7741\n408\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([75.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([98.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([98.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([79.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([82.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([81.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([91.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([77.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([56.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([71.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([77.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([75.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([68.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([82.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([98.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([73.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([72.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([74.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([81.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([81.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[83.0051]], grad_fn=<ToCopyBackward0>) tensor([74.])\nepoch is 1, loss test is 9.530204772949219\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([73.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([98.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([95.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([73.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([94.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([81.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([79.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([74.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([98.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([83.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([94.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([62.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([72.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([77.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([74.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([73.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([77.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([79.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([75.])\ntensor([[82.8169]], grad_fn=<ToCopyBackward0>) tensor([60.])\nepoch is 2, loss test is 9.534332275390625\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([82.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([73.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([91.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([98.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([98.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([98.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([60.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([72.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([75.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([98.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([94.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([98.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([98.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([50.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([82.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([98.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([79.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([60.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([79.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([72.])\ntensor([[82.9126]], grad_fn=<ToCopyBackward0>) tensor([87.])\nepoch is 3, loss test is 9.531768798828125\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/2714936702.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0mloss_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_17/2714936702.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    218\u001b[0m     ]\n\u001b[1;32m    219\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Adam对学习率不太敏感\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# enumerate 将一个可遍历的数据对象组合为一个索引序列\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0mimage1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mimage2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_17/2714936702.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0minput_one_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomAffine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColorJitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrightness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontrast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_one_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0minput_two_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomAffine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColorJitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrightness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontrast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_two_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minput_one_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_two_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"class SiameseNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.cnn1 = nn.Sequential(\n            nn.BatchNorm2d(1,affine=True), # B*C*H*W\n            nn.Conv2d(1, 64, kernel_size=3, padding=1, bias=False),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 64 * 32 * 32\n        )\n        self.cnn2 = nn.Sequential(\n            nn.BatchNorm2d(64,affine=True), # B*C*H*W\n            nn.Conv2d(64, 128, kernel_size=5, padding=2, bias=False),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            # nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            # nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 128 * 16 * 16\n        )\n        self.cnn3 = nn.Sequential(\n            nn.BatchNorm2d(128,affine=True), # B*C*H*W\n            nn.Conv2d(128, 256, kernel_size=3, padding=1, bias=False),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            # nn.ReLU(inplace=True),\n            # nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            # nn.ReLU(inplace=True),\n            # nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 256 * 8 * 8\n        )\n\n        self.fc1 = nn.Sequential(\n            nn.Linear(256 * 8 * 8, 1000, bias=False),\n            nn.Linear(1000, 100, bias=False),\n            # nn.ReLU(inplace=True),\n            # nn.Linear(20, 1)\n        )\n\n        self.fc2 = nn.Sequential(\n            nn.Linear(1, 4),\n            nn.ReLU(inplace=True),\n            nn.Linear(4, 1)\n        )\n        # for m in self.modules():\n        #     if isinstance(m,nn.Conv2d):\n        #         nn.init.kaiming_normal_(m.weight.data,0.3)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0.3)\n        #     elif isinstance(m,nn.Linear):\n        #         nn.init.kaiming_normal_(m.weight.data)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0.5)\n        #     elif isinstance(m,nn.BatchNorm2d):\n        #         nn.init.kaiming_normal_(m.weight.data,0.3)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0)\n    def forward_once(self, x):\n        B, C, H, W = x.shape\n        output = self.cnn1(x)\n        output = self.cnn2(output)\n        output = self.cnn3(output)\n        output = output.view(B, 256*8*8)\n        output = self.fc1(output)\n        output = nn.Sigmoid()(output)\n        return output\n\n    def forward(self, input1, input2):\n        B, C, H, W = input1.shape\n        output1 = self.forward_once(input1)\n        # 7*20\n        output2 = self.forward_once(input2)\n        output3 = nn.functional.cosine_similarity(output1, output2, dim=1)\n        output3 = output3.resize(B, 1)\n        output4 = self.fc2(output3)\n        # output4=output3\n        output4 = output4.resize(1, B)\n        output4 = nn.Sigmoid()(output4)\n        output4 = output4*100\n        return output4\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, path):\n        super(CustomDataset,self).__init__()\n        # path=\"E:/MyProject/\"\n        self.path0=\"../input/standard/standard/\"\n        self.path1=\"../input/train1/train1/\"\n        self.path2=\"../input/train2/train2/\"\n        self.index0=json.loads(open(\"../input/index-standard/index_standard.json\",'r',encoding='utf-8').read())\n        self.index1=json.loads(open(\"../input/index-train1/index_train1.json\",'r',encoding='utf-8').read())\n        self.index2=json.loads(open(\"../input/index-train2/index_train2.json\",'r',encoding='utf-8').read())\n        self.dframe0=pd.DataFrame(self.index0)\n\n    def __getitem__(self,index):\n        if (index<len(self.index1)):\n            word=self.index1[index][\"word\"]\n            filename1=self.path1+self.index1[index][\"filename\"]\n            score=self.index1[index][\"score\"]\n        else:\n            index-=len(self.index1)\n            if (index<len(self.index2)*6):\n                word=self.index2[index//6][\"word\"]\n                filename1=self.path2+self.index1[index//6][\"filename\"]\n                score=self.index2[index//6][\"score\"]\n        item = self.dframe0.loc[self.dframe0['word']==word]\n        fileName = item[\"filename\"].values[0]\n        filename2 = self.path0 + fileName\n        #filename2=self.path0+self.dframe0.loc[self.dframe0[\"word\"]==word][\"filename\"][1]\n        \n        input_one = Image.open(filename2)\n        input_one_np = numpy.array(input_one)\n        input_one=numpy.where(numpy.sum(input_one_np,axis=2)==3*255,0,1)\n        # print(input_one.shape)\n\n        input_two = Image.open(filename1)\n        input_two_np = numpy.array(input_two)\n        input_two=numpy.where(input_two_np==255,0,1)\n        # print(input_two.shape)\n        \n        \n        input_one_tensor = torch.tensor(input_one, dtype=torch.float32).unsqueeze(0)\n        input_two_tensor = torch.tensor(input_two, dtype=torch.float32).unsqueeze(0)\n        label_tensor = torch.tensor(int(score),dtype=torch.float32)\n        # input_one.cuda()\n        # input_two.cuda()\n        # label.cuda()\n        input_one_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_one_tensor)\n        input_two_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_two_tensor)\n        return input_one_tensor,input_two_tensor, label_tensor\n\n    def __len__(self):\n        len_1=len(self.index1)\n        len_2=len(self.index2)*6\n        return len_1+len_2\n\ndataset = CustomDataset(path=\"E:/MyProject/\")\nprint(len(dataset))\n#train_dataset,test_dataset=data.random_split(dataset,torch(len(dataset)/100*95),len(dataset)-torch.floor(len(dataset)/100*95))\nn_train = int(len(dataset)/100*95)\nn_val = len(dataset) - n_train\ntrain_dataset,test_dataset=data.random_split(dataset,[n_train, n_val])\nprint(len(train_dataset))\nprint(len(test_dataset))\ntrain_dataloader=data.DataLoader(\n    train_dataset,\n    batch_size=64,    \n    shuffle=True,\n    #num_worders=8,\n    pin_memory=True,\n    drop_last=True\n)\ntest_dataloader=data.DataLoader(\n    test_dataset,\n    batch_size=1,\n    #num_worders=8,\n    shuffle=True,\n    pin_memory=True\n)\n\n# net\n\nsiamese=torch.load(\"./model.pth\").cpu()\nprint (len(test_dataset))\naccuracy=0\nfor i,(image1,image2,labels) in enumerate(test_dataloader):\n    \n    outputs=siamese(image1,image2)\n    pred=outputs\n\n    labels=labels.cpu().numpy()[0]\n    pred=pred.cpu().detach().numpy()[0]\n    # batchsize*1*28*28\n    # 通道数（灰度图=1） 在显示时应放在最后\n\n    print(\"label\",labels)\n    print(\"pred\",pred)\n\naccuracy=torch.sqrt(accuracy/len(test_dataset))\n# 方差\nprint(\"accuracy is {}\".format(accuracy))\n      ","metadata":{},"execution_count":null,"outputs":[]}]}