{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# -*- encoding: utf-8 -*-\n# siemese.py\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nfrom torch.utils import data\nimport cv2\nimport json\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy\nfrom PIL import Image\nimport pandas as pd\nfrom ast import Add\nfrom logging import critical\nfrom multiprocessing import reduction\nfrom turtle import forward\n\n#from siamese_net import SiameseNetwork\n#from CustomDataset import CustomDataset\n","metadata":{"execution":{"iopub.status.busy":"2022-10-21T12:09:16.832360Z","iopub.execute_input":"2022-10-21T12:09:16.832824Z","iopub.status.idle":"2022-10-21T12:09:19.684163Z","shell.execute_reply.started":"2022-10-21T12:09:16.832727Z","shell.execute_reply":"2022-10-21T12:09:19.682992Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# 计算平均值，方差\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, path):\n        super(CustomDataset,self).__init__()\n        # path=\"E:/MyProject/\"\n        self.path0=\"../input/standard/standard/\"\n        self.path1=\"../input/train1/train1/\"\n        self.path2=\"../input/train2/train2/\"\n        self.index0=json.loads(open(\"../input/index-standard/index_standard.json\",'r',encoding='utf-8').read())\n        self.index1=json.loads(open(\"../input/index-train1/index_train1.json\",'r',encoding='utf-8').read())\n        self.index2=json.loads(open(\"../input/index-train2/index_train2.json\",'r',encoding='utf-8').read())\n        self.dframe0=pd.DataFrame(self.index0)\n\n    def __getitem__(self,index):\n        if (index<len(self.index1)//4):\n            word=self.index1[index][\"word\"]\n            filename1=self.path1+self.index1[index][\"filename\"]\n            score=self.index1[index][\"score\"]\n        else:\n            index-=len(self.index1)//4\n            if (index<len(self.index2)*6):\n                word=self.index2[index//6][\"word\"]\n                filename1=self.path2+self.index1[index//6][\"filename\"]\n                score=self.index2[index//6][\"score\"]\n        item = self.dframe0.loc[self.dframe0['word']==word]\n        fileName = item[\"filename\"].values[0]\n        filename2 = self.path0 + fileName\n        #filename2=self.path0+self.dframe0.loc[self.dframe0[\"word\"]==word][\"filename\"][1]\n        \n        input_one = Image.open(filename2)\n        input_one_np = numpy.array(input_one)\n        input_one=numpy.where(numpy.sum(input_one_np,axis=2)==3*255,0,1)\n        # print(input_one.shape)\n\n        input_two = Image.open(filename1)\n        input_two_np = numpy.array(input_two)\n        input_two=numpy.where(input_two_np==255,0,1)\n        # print(input_two.shape)\n        \n        \n        input_one_tensor = torch.tensor(input_one, dtype=torch.float32).unsqueeze(0)\n        input_two_tensor = torch.tensor(input_two, dtype=torch.float32).unsqueeze(0)\n        label_tensor = torch.tensor(int(score),dtype=torch.float32)\n        # input_one.cuda()\n        # input_two.cuda()\n        # label.cuda()\n        input_one_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_one_tensor)\n        input_two_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_two_tensor)\n        return input_one_tensor,input_two_tensor, label_tensor\n\n    def __len__(self):\n        len_1=len(self.index1)//4\n        len_2=len(self.index2)*6\n        return len_1+len_2\n\ndataset = CustomDataset(path=\"E:/MyProject/\")\nl=len(dataset)\ncal1=torch.tensor(0)\ncal2=torch.tensor(0)\nfor i in range(l):\n    a,b,c=dataset.__getitem__(i)\n    cal1=cal1+c\naverage=cal1/l\nfor i in range(l):\n    a,b,c=dataset.__getitem__(i)\n    cal2=cal2+(c-average)*(c-average)\ncal2=cal2/l\ncal2=torch.sqrt(cal2)\nprint(average,cal2)","metadata":{"_uuid":"c9b93d6c-1c2e-4b24-be5c-52e07b4952b9","_cell_guid":"f1e51bb1-f642-4050-a1d4-d5d7f8c029a3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-10-21T11:02:52.347269Z","iopub.status.idle":"2022-10-21T11:02:52.347789Z","shell.execute_reply.started":"2022-10-21T11:02:52.347517Z","shell.execute_reply":"2022-10-21T11:02:52.347541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# all\naverage=torch.tensor(83.0401)\nvariance=torch.tensor(10.2655)\nclass SiameseNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.cnn1 = nn.Sequential(\n            nn.BatchNorm2d(1,affine=True), # B*C*H*W\n            nn.Conv2d(1, 64, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 64 * 32 * 32\n        )\n        self.cnn2 = nn.Sequential(\n            nn.BatchNorm2d(64,affine=True), # B*C*H*W\n            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            # nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            # nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 128 * 16 * 16\n        )\n        self.cnn3 = nn.Sequential(\n            nn.BatchNorm2d(128,affine=True), # B*C*H*W\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            # nn.ReLU(inplace=True),\n            # nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 256 * 8 * 8\n        )\n        self.cnn4 = nn.Sequential(\n            nn.BatchNorm2d(256,affine=True), # B*C*H*W\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 512 * 4 * 4\n        )\n\n        self.fc1 = nn.Sequential(\n            nn.Linear(512 * 4 * 4, 100, bias=True),\n#             nn.Linear(1000, 100, bias=True),\n            # nn.ReLU(inplace=True),\n            # nn.Linear(20, 1)\n        )\n\n        self.fc2 = nn.Sequential(\n            nn.Linear(100, 1, bias=False),\n        )\n        # for m in self.modules():\n        #     if isinstance(m,nn.Conv2d):\n        #         nn.init.kaiming_normal_(m.weight.data,0.3)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0.3)\n        #     elif isinstance(m,nn.Linear):\n        #         nn.init.kaiming_normal_(m.weight.data)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0.5)\n        #     elif isinstance(m,nn.BatchNorm2d):\n        #         nn.init.kaiming_normal_(m.weight.data,0.3)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0)\n    def forward_once(self, x):\n        B, C, H, W = x.shape\n        output = self.cnn1(x)\n        output = self.cnn2(output)\n        output = self.cnn3(output)\n        output = self.cnn4(output)\n        output = output.view(B, 512*4*4)\n        output = self.fc1(output)\n#         output = output.view(B,100)\n#         output = nn.BatchNorm1d(100,eps=1e-4,affine=True).cuda()(output) # B*C*H*W\n#         output = nn.Sigmoid()(output)\n        return output\n\n    def forward(self, input1, input2):\n        B, C, H, W = input1.shape\n        output1 = self.forward_once(input1)\n        # 7*20\n        output2 = self.forward_once(input2)\n#         output3 = nn.functional.cosine_similarity(output1, output2, dim=1)-torch.ones((1,B)).cuda()*0.995\n#         output3=torch.abs(output2-output1).sum(dim=1)\n#         output3=(output1-output2).norm(2,dim=1,keepdim=True)\n        output3=output1-output2\n        output3=self.fc2(output3)\n#         output3 = output3.resize(B, 1)\n        output4=output3\n        output4=output4*variance+average\n        return output4\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, path):\n        super(CustomDataset,self).__init__()\n        # path=\"E:/MyProject/\"\n        self.path0=\"../input/standard/standard/\"\n        self.path1=\"../input/train1/train1/\"\n        self.path2=\"../input/train2/train2/\"\n        self.index0=json.loads(open(\"../input/index-standard/index_standard.json\",'r',encoding='utf-8').read())\n        self.index1=json.loads(open(\"../input/index-train1/index_train1.json\",'r',encoding='utf-8').read())\n        self.index2=json.loads(open(\"../input/index-train2/index_train2.json\",'r',encoding='utf-8').read())\n        self.dframe0=pd.DataFrame(self.index0)\n#         self.len1=len(self.index1)//4\n        self.len1=0\n        self.len2=len(self.index2)*6\n    def __getitem__(self,index):\n        if (index<self.len1):\n            word=self.index1[index][\"word\"]\n            filename1=self.path1+self.index1[index][\"filename\"]\n            score=self.index1[index][\"score\"]\n        else:\n            index-=self.len1\n            if (index<len(self.index2)*6):\n                word=self.index2[index//6][\"word\"]\n                filename1=self.path2+self.index1[index//6][\"filename\"]\n                score=self.index2[index//6][\"score\"]\n        item = self.dframe0.loc[self.dframe0['word']==word]\n        fileName = item[\"filename\"].values[0]\n        filename2 = self.path0 + fileName\n        #filename2=self.path0+self.dframe0.loc[self.dframe0[\"word\"]==word][\"filename\"][1]\n        \n        input_one = Image.open(filename2)\n        input_one_np = numpy.array(input_one)\n        input_one=numpy.where(numpy.sum(input_one_np,axis=2)==3*255,0,1)\n        # print(input_one.shape)\n\n        input_two = Image.open(filename1)\n        input_two_np = numpy.array(input_two)\n        input_two=numpy.where(input_two_np==255,0,1)\n        # print(input_two.shape)\n        \n        \n        input_one_tensor = torch.tensor(input_one, dtype=torch.float32).unsqueeze(0)\n        input_two_tensor = torch.tensor(input_two, dtype=torch.float32).unsqueeze(0)\n        label_tensor = torch.tensor(int(score),dtype=torch.float32)\n        # input_one.cuda()\n        # input_two.cuda()\n        # label.cuda()\n        input_one_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_one_tensor)\n        input_two_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_two_tensor)\n        return input_one_tensor,input_two_tensor, label_tensor\n\n    def __len__(self):\n#         len_1=len(self.index1)//4\n#         len_1=0\n#         len_2=len(self.index2)*6\n        return self.len1+self.len2\n\n# train.py\ndataset = CustomDataset(path=\"E:/MyProject/\")\nprint(len(dataset))\n#train_dataset,test_dataset=data.random_split(dataset,torch(len(dataset)/100*95),len(dataset)-torch.floor(len(dataset)/100*95))\nn_train = int(len(dataset)/100*95)\nn_val = len(dataset) - n_train\ntrain_dataset,test_dataset=data.random_split(dataset,[n_train, n_val])\nprint(len(train_dataset))\nprint(len(test_dataset))\ntrain_dataloader=data.DataLoader(\n    train_dataset,\n    batch_size=64,    \n    shuffle=True,\n    #num_worders=8,\n    pin_memory=True,\n    drop_last=True\n)\ntest_dataloader=data.DataLoader(\n    test_dataset,\n    batch_size=1,\n    #num_worders=8,\n    shuffle=True,\n    pin_memory=True\n)\n\n\n# net\n\nsiamese=torch.load(\"./model.pth\")\n# siamese=SiameseNetwork()\nsiamese=siamese.cuda()\n#siamese =SiameseNetwork().cuda() #定义模型以致GPU\n\n# loss\n# loss_func = ContrastiveLoss() #定义损失函数\nloss_func = torch.nn.MSELoss()\n\n\naverage=torch.tensor(83.0401)\nvariance=torch.tensor(10.2655)\n\ntrain_list=[siamese.cnn1,siamese.cnn2,siamese.cnn3,siamese.fc1,siamese.fc2]\ndef train(a,b):\n    params=[\n        {\"params\":siamese.cnn1.parameters(),\"lr\":a},\n        {\"params\":siamese.cnn2.parameters(),\"lr\":a},\n        {\"params\":siamese.cnn3.parameters(),\"lr\":a},\n        {\"params\":siamese.cnn4.parameters(),\"lr\":a},\n        {\"params\":siamese.fc1.parameters(),\"lr\":b},\n        {\"params\":siamese.fc2.parameters(),\"lr\":b},\n    ]\n    optimizer=torch.optim.Adam(params) # Adam对学习率不太敏感\n    for i, (image1,image2,labels) in enumerate(train_dataloader): # enumerate 将一个可遍历的数据对象组合为一个索引序列\n        image1=image1.cuda()\n        image2=image2.cuda()\n        \n        labels=labels.cuda()\n#         print(image1.shape)\n#         print(image2.shape)\n        \n        # print(image1.shape, image2.shape)\n        optimizer.zero_grad()\n        outputs=siamese(image1,image2)\n        # print(outputs.shape, labels.shape)\n        loss=loss_func(outputs,labels)\n        loss.backward()\n        optimizer.step()\n#         print(\"epoch is {}, ite is {}/{}, loss is {}\".format(epoch+1, i, len(train_dataset) // 64, loss.item()))\n    torch.save(siamese,\"./model.pth\")\n    \n# training\n\nfor epoch in range(10): #epoch one usage of whole dataset\n    train(1e-3,1e-4)\n    train(1e-2,0)\n    train(0,1e-3)\n        \n    loss_test=0\n    lst=[]\n    for i,(image1,image2,labels) in enumerate(test_dataloader):\n        image1=image1.cuda()\n        image2=image2.cuda()\n        outputs=siamese(image1,image2)\n        outputs=outputs.cpu()\n        labels=labels.to(torch.float32)\n        #[batchsize]\n        #outputs=batchsize*cls_num\n        now=(outputs-labels)*(outputs-labels)\n        lst.append(outputs)\n        loss_test += now\n        if (i % 10 ==0):\n            print(outputs,labels)\n        # _, pred=outputs.max(dim=1)\n    loss_test=torch.sqrt(loss_test/len(test_dataloader))\n    print(\"epoch is {}, loss test is {}\".format(epoch+1,loss_test.item()))\n    \n    lst=torch.tensor(lst)\n    print(\"mean={},std={}\".format(torch.mean(lst),torch.std(lst)))\n    # input(\"next\")\n\ntorch.save(siamese,\"./model.pth\")\n\n# eval/test\n# save\n\n# load\n# inference","metadata":{"execution":{"iopub.status.busy":"2022-10-21T13:55:30.924544Z","iopub.execute_input":"2022-10-21T13:55:30.925172Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"7038\n6686\n352\ntensor([[79.9451]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[80.7277]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[80.8617]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[80.7189]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[80.7888]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[81.2532]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[82.2914]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[81.0808]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[81.1539]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[81.4759]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[80.8812]], grad_fn=<ToCopyBackward0>) tensor([75.])\ntensor([[81.8496]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[82.5381]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[81.5073]], grad_fn=<ToCopyBackward0>) tensor([79.])\ntensor([[82.6572]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[81.9838]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[80.3032]], grad_fn=<ToCopyBackward0>) tensor([82.])\ntensor([[82.4614]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[80.4896]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[80.3572]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[81.2321]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[81.0172]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[81.1024]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[78.7793]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[80.1650]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[79.5172]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[78.0594]], grad_fn=<ToCopyBackward0>) tensor([72.])\ntensor([[81.4518]], grad_fn=<ToCopyBackward0>) tensor([63.])\ntensor([[83.5034]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[81.9015]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[78.9579]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[79.3851]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[81.5936]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[79.5224]], grad_fn=<ToCopyBackward0>) tensor([79.])\ntensor([[81.4760]], grad_fn=<ToCopyBackward0>) tensor([66.])\ntensor([[81.0574]], grad_fn=<ToCopyBackward0>) tensor([84.])\nepoch is 1, loss test is 9.616291999816895\nmean=81.10847473144531,std=1.3508541584014893\ntensor([[78.8713]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[80.1194]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[85.0293]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[79.5389]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[78.9146]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[82.2411]], grad_fn=<ToCopyBackward0>) tensor([91.])\ntensor([[77.4976]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[75.4543]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[83.1741]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[83.6243]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[79.4010]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[81.3148]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[80.1455]], grad_fn=<ToCopyBackward0>) tensor([82.])\ntensor([[79.0255]], grad_fn=<ToCopyBackward0>) tensor([63.])\ntensor([[81.5390]], grad_fn=<ToCopyBackward0>) tensor([74.])\ntensor([[79.5896]], grad_fn=<ToCopyBackward0>) tensor([79.])\ntensor([[82.0230]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[80.4006]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[79.3905]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[81.0136]], grad_fn=<ToCopyBackward0>) tensor([79.])\ntensor([[82.1118]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[81.5522]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[81.1286]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[78.8809]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[78.8212]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[77.4489]], grad_fn=<ToCopyBackward0>) tensor([72.])\ntensor([[81.9912]], grad_fn=<ToCopyBackward0>) tensor([94.])\ntensor([[82.9932]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[78.4813]], grad_fn=<ToCopyBackward0>) tensor([74.])\ntensor([[80.8300]], grad_fn=<ToCopyBackward0>) tensor([81.])\ntensor([[84.1030]], grad_fn=<ToCopyBackward0>) tensor([74.])\ntensor([[77.8243]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[81.5428]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[81.4439]], grad_fn=<ToCopyBackward0>) tensor([61.])\ntensor([[79.5424]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[81.1127]], grad_fn=<ToCopyBackward0>) tensor([70.])\nepoch is 2, loss test is 9.671887397766113\nmean=80.34066009521484,std=1.984372854232788\ntensor([[83.0445]], grad_fn=<ToCopyBackward0>) tensor([94.])\ntensor([[74.2398]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[79.2508]], grad_fn=<ToCopyBackward0>) tensor([82.])\ntensor([[78.4562]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[81.3983]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[81.1241]], grad_fn=<ToCopyBackward0>) tensor([91.])\ntensor([[80.7076]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[77.8047]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[75.9987]], grad_fn=<ToCopyBackward0>) tensor([83.])\ntensor([[78.1935]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[75.3824]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[80.8054]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[80.3195]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[75.1992]], grad_fn=<ToCopyBackward0>) tensor([72.])\ntensor([[77.9488]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[77.8906]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[78.0865]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[76.0184]], grad_fn=<ToCopyBackward0>) tensor([83.])\ntensor([[78.3302]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[79.7580]], grad_fn=<ToCopyBackward0>) tensor([71.])\ntensor([[80.9871]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[80.6679]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[76.5378]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[77.6960]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[77.0021]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[83.9845]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[79.6588]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[80.7704]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[78.6805]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[80.3011]], grad_fn=<ToCopyBackward0>) tensor([75.])\ntensor([[78.6205]], grad_fn=<ToCopyBackward0>) tensor([79.])\ntensor([[80.6334]], grad_fn=<ToCopyBackward0>) tensor([83.])\ntensor([[82.6365]], grad_fn=<ToCopyBackward0>) tensor([94.])\ntensor([[75.7059]], grad_fn=<ToCopyBackward0>) tensor([69.])\ntensor([[78.7825]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[78.0489]], grad_fn=<ToCopyBackward0>) tensor([78.])\nepoch is 3, loss test is 9.744361877441406\nmean=79.49256134033203,std=2.022463321685791\ntensor([[82.2041]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[81.9352]], grad_fn=<ToCopyBackward0>) tensor([94.])\ntensor([[78.5577]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[80.4692]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[82.5797]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[76.9386]], grad_fn=<ToCopyBackward0>) tensor([91.])\ntensor([[78.8340]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[79.8451]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[76.7248]], grad_fn=<ToCopyBackward0>) tensor([97.])\ntensor([[80.8117]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[80.9877]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[79.6111]], grad_fn=<ToCopyBackward0>) tensor([60.])\ntensor([[78.8754]], grad_fn=<ToCopyBackward0>) tensor([82.])\ntensor([[79.6437]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[81.9240]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[79.0575]], grad_fn=<ToCopyBackward0>) tensor([63.])\ntensor([[79.3180]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[79.9597]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[76.6720]], grad_fn=<ToCopyBackward0>) tensor([72.])\ntensor([[81.4052]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[81.4410]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[80.9141]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[81.9318]], grad_fn=<ToCopyBackward0>) tensor([83.])\ntensor([[80.5927]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[82.1578]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[80.1770]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[82.0256]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[78.7798]], grad_fn=<ToCopyBackward0>) tensor([79.])\ntensor([[78.2788]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[80.9089]], grad_fn=<ToCopyBackward0>) tensor([73.])\ntensor([[82.0632]], grad_fn=<ToCopyBackward0>) tensor([83.])\ntensor([[79.0530]], grad_fn=<ToCopyBackward0>) tensor([69.])\ntensor([[82.0075]], grad_fn=<ToCopyBackward0>) tensor([94.])\ntensor([[80.7273]], grad_fn=<ToCopyBackward0>) tensor([73.])\ntensor([[82.7124]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[79.5277]], grad_fn=<ToCopyBackward0>) tensor([87.])\nepoch is 4, loss test is 9.66050910949707\nmean=80.2466049194336,std=1.6976476907730103\ntensor([[81.6495]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[80.8248]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[82.2152]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[81.4046]], grad_fn=<ToCopyBackward0>) tensor([82.])\ntensor([[81.3143]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[85.8970]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[82.5191]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[78.9756]], grad_fn=<ToCopyBackward0>) tensor([91.])\ntensor([[80.7523]], grad_fn=<ToCopyBackward0>) tensor([73.])\ntensor([[82.3081]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[82.9767]], grad_fn=<ToCopyBackward0>) tensor([82.])\ntensor([[82.2827]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[80.8918]], grad_fn=<ToCopyBackward0>) tensor([82.])\ntensor([[79.9259]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[79.7464]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[81.8346]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[82.8454]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[81.0049]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[83.0915]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[81.9022]], grad_fn=<ToCopyBackward0>) tensor([73.])\ntensor([[82.8085]], grad_fn=<ToCopyBackward0>) tensor([75.])\ntensor([[77.9442]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[83.5755]], grad_fn=<ToCopyBackward0>) tensor([94.])\ntensor([[83.8035]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[83.4744]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[81.0288]], grad_fn=<ToCopyBackward0>) tensor([75.])\ntensor([[77.8311]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[80.7621]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[77.9261]], grad_fn=<ToCopyBackward0>) tensor([91.])\ntensor([[82.8605]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[80.4798]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[81.5836]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[80.6444]], grad_fn=<ToCopyBackward0>) tensor([60.])\ntensor([[82.9487]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[81.0374]], grad_fn=<ToCopyBackward0>) tensor([69.])\ntensor([[77.7045]], grad_fn=<ToCopyBackward0>) tensor([86.])\nepoch is 5, loss test is 9.55416488647461\nmean=81.21211242675781,std=1.4567900896072388\ntensor([[81.5836]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[80.5838]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[81.1545]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[82.7923]], grad_fn=<ToCopyBackward0>) tensor([83.])\ntensor([[81.2297]], grad_fn=<ToCopyBackward0>) tensor([91.])\ntensor([[83.7769]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[83.5257]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[83.6241]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[81.3143]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[81.4369]], grad_fn=<ToCopyBackward0>) tensor([71.])\ntensor([[81.3669]], grad_fn=<ToCopyBackward0>) tensor([67.])\ntensor([[81.4740]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[80.3496]], grad_fn=<ToCopyBackward0>) tensor([83.])\ntensor([[81.4125]], grad_fn=<ToCopyBackward0>) tensor([83.])\ntensor([[81.1581]], grad_fn=<ToCopyBackward0>) tensor([82.])\ntensor([[81.4225]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[79.4908]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[81.2666]], grad_fn=<ToCopyBackward0>) tensor([73.])\ntensor([[82.2458]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[80.8413]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[82.1025]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[80.2304]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[83.2435]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[82.4356]], grad_fn=<ToCopyBackward0>) tensor([72.])\ntensor([[83.3679]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[81.5718]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[82.9461]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[80.9108]], grad_fn=<ToCopyBackward0>) tensor([72.])\ntensor([[81.6219]], grad_fn=<ToCopyBackward0>) tensor([63.])\ntensor([[82.1681]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[80.6279]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[81.2447]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[81.6341]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[82.6306]], grad_fn=<ToCopyBackward0>) tensor([71.])\ntensor([[85.0029]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[80.1604]], grad_fn=<ToCopyBackward0>) tensor([84.])\nepoch is 6, loss test is 9.543028831481934\nmean=81.3273696899414,std=1.3126775026321411\ntensor([[82.2451]], grad_fn=<ToCopyBackward0>) tensor([72.])\ntensor([[80.0664]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[83.4235]], grad_fn=<ToCopyBackward0>) tensor([94.])\ntensor([[84.3454]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[80.1982]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[80.8006]], grad_fn=<ToCopyBackward0>) tensor([77.])\ntensor([[79.2154]], grad_fn=<ToCopyBackward0>) tensor([91.])\ntensor([[78.1507]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[81.0737]], grad_fn=<ToCopyBackward0>) tensor([94.])\ntensor([[80.2694]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[82.8664]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[79.0786]], grad_fn=<ToCopyBackward0>) tensor([55.])\ntensor([[81.5042]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[81.5470]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[80.1301]], grad_fn=<ToCopyBackward0>) tensor([60.])\ntensor([[80.2760]], grad_fn=<ToCopyBackward0>) tensor([79.])\ntensor([[78.3670]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[81.0159]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[79.2018]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[78.5244]], grad_fn=<ToCopyBackward0>) tensor([73.])\ntensor([[78.9579]], grad_fn=<ToCopyBackward0>) tensor([83.])\ntensor([[80.6809]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[83.6962]], grad_fn=<ToCopyBackward0>) tensor([66.])\ntensor([[80.7345]], grad_fn=<ToCopyBackward0>) tensor([50.])\ntensor([[81.2002]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[79.0746]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[80.8637]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[79.7272]], grad_fn=<ToCopyBackward0>) tensor([82.])\ntensor([[79.3418]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[78.8869]], grad_fn=<ToCopyBackward0>) tensor([60.])\ntensor([[80.5912]], grad_fn=<ToCopyBackward0>) tensor([79.])\ntensor([[78.7905]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[83.5670]], grad_fn=<ToCopyBackward0>) tensor([94.])\ntensor([[78.5149]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[80.3403]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[81.9708]], grad_fn=<ToCopyBackward0>) tensor([76.])\nepoch is 7, loss test is 9.514103889465332\nmean=80.50222778320312,std=1.5632615089416504\ntensor([[79.9127]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[80.5800]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[83.4449]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[78.1818]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[79.4151]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[82.4562]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[84.2026]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[80.5789]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[81.0067]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[81.6873]], grad_fn=<ToCopyBackward0>) tensor([73.])\ntensor([[77.2263]], grad_fn=<ToCopyBackward0>) tensor([55.])\ntensor([[79.6851]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[82.7097]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[84.8940]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[77.4798]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[80.7373]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[80.0624]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[81.1690]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[79.0349]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[84.1081]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[82.1943]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[81.9002]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[77.1554]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[80.6453]], grad_fn=<ToCopyBackward0>) tensor([71.])\ntensor([[80.3908]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[77.1037]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[83.0004]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[81.3717]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[83.3435]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[81.4107]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[78.8040]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[79.9067]], grad_fn=<ToCopyBackward0>) tensor([64.])\ntensor([[79.7089]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[72.2829]], grad_fn=<ToCopyBackward0>) tensor([72.])\ntensor([[77.5581]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[80.5345]], grad_fn=<ToCopyBackward0>) tensor([85.])\nepoch is 8, loss test is 9.492976188659668\nmean=80.03974151611328,std=2.0094528198242188\ntensor([[76.6619]], grad_fn=<ToCopyBackward0>) tensor([72.])\ntensor([[75.4127]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[79.6148]], grad_fn=<ToCopyBackward0>) tensor([79.])\ntensor([[79.8013]], grad_fn=<ToCopyBackward0>) tensor([63.])\ntensor([[82.5751]], grad_fn=<ToCopyBackward0>) tensor([83.])\ntensor([[77.8502]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[79.7139]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[82.7266]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[81.4239]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[82.1259]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[80.5308]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[76.8385]], grad_fn=<ToCopyBackward0>) tensor([83.])\ntensor([[79.9807]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[82.7806]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[81.1109]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[82.3952]], grad_fn=<ToCopyBackward0>) tensor([82.])\ntensor([[80.2358]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[80.8413]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[81.9468]], grad_fn=<ToCopyBackward0>) tensor([65.])\ntensor([[81.2747]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[80.5618]], grad_fn=<ToCopyBackward0>) tensor([73.])\ntensor([[77.8098]], grad_fn=<ToCopyBackward0>) tensor([61.])\ntensor([[78.5322]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[81.8209]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[80.4007]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[80.6465]], grad_fn=<ToCopyBackward0>) tensor([79.])\ntensor([[82.7008]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[77.9606]], grad_fn=<ToCopyBackward0>) tensor([62.])\ntensor([[82.9722]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[83.0403]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[81.8146]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[81.8872]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[80.7307]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[79.6003]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[80.2173]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[80.9316]], grad_fn=<ToCopyBackward0>) tensor([85.])\nepoch is 9, loss test is 9.46218204498291\nmean=80.5687255859375,std=1.556761384010315\n","output_type":"stream"}]},{"cell_type":"code","source":"average=torch.tensor(83.0401)\nvariance=torch.tensor(10.2655)\nclass SiameseNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.cnn1 = nn.Sequential(\n            nn.BatchNorm2d(1,affine=True), # B*C*H*W\n            nn.Conv2d(1, 64, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 64 * 32 * 32\n        )\n        self.cnn2 = nn.Sequential(\n            nn.BatchNorm2d(64,affine=True), # B*C*H*W\n            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            # nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            # nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 128 * 16 * 16\n        )\n        self.cnn3 = nn.Sequential(\n            nn.BatchNorm2d(128,affine=True), # B*C*H*W\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            # nn.ReLU(inplace=True),\n            # nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 256 * 8 * 8\n        )\n        self.cnn4 = nn.Sequential(\n            nn.BatchNorm2d(256,affine=True), # B*C*H*W\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 512 * 4 * 4\n        )\n\n        self.fc1 = nn.Sequential(\n            nn.Linear(512 * 4 * 4, 100, bias=True),\n#             nn.Linear(1000, 100, bias=True),\n            # nn.ReLU(inplace=True),\n            # nn.Linear(20, 1)\n        )\n\n        self.fc2 = nn.Sequential(\n            nn.Linear(100, 1, bias=False),\n        )\n        # for m in self.modules():\n        #     if isinstance(m,nn.Conv2d):\n        #         nn.init.kaiming_normal_(m.weight.data,0.3)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0.3)\n        #     elif isinstance(m,nn.Linear):\n        #         nn.init.kaiming_normal_(m.weight.data)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0.5)\n        #     elif isinstance(m,nn.BatchNorm2d):\n        #         nn.init.kaiming_normal_(m.weight.data,0.3)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0)\n    def forward_once(self, x):\n        B, C, H, W = x.shape\n        output = self.cnn1(x)\n        output = self.cnn2(output)\n        output = self.cnn3(output)\n        output = self.cnn4(output)\n        output = output.view(B, 512*4*4)\n        output = self.fc1(output)\n#         output = output.view(B,100)\n#         output = nn.BatchNorm1d(100,eps=1e-4,affine=True).cuda()(output) # B*C*H*W\n#         output = nn.Sigmoid()(output)\n        return output\n\n    def forward(self, input1, input2):\n        B, C, H, W = input1.shape\n        output1 = self.forward_once(input1)\n        # 7*20\n        output2 = self.forward_once(input2)\n#         output3 = nn.functional.cosine_similarity(output1, output2, dim=1)-torch.ones((1,B)).cuda()*0.995\n#         output3=torch.abs(output2-output1).sum(dim=1)\n#         output3=(output1-output2).norm(2,dim=1,keepdim=True)\n        output3=output1-output2\n        output3=self.fc2(output3)\n#         output3 = output3.resize(B, 1)\n        output4=output3\n        output4=output4*variance+average\n        return output4\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, path):\n        super(CustomDataset,self).__init__()\n        # path=\"E:/MyProject/\"\n        self.path0=\"../input/standard/standard/\"\n        self.path1=\"../input/train1/train1/\"\n        self.path2=\"../input/train2/train2/\"\n        self.index0=json.loads(open(\"../input/index-standard/index_standard.json\",'r',encoding='utf-8').read())\n        self.index1=json.loads(open(\"../input/index-train1/index_train1.json\",'r',encoding='utf-8').read())\n        self.index2=json.loads(open(\"../input/index-train2/index_train2.json\",'r',encoding='utf-8').read())\n        self.dframe0=pd.DataFrame(self.index0)\n#         self.len1=len(self.index1)//4\n        self.len1=0\n        self.len2=len(self.index2)*6\n    def __getitem__(self,index):\n        if (index<self.len1):\n            word=self.index1[index][\"word\"]\n            filename1=self.path1+self.index1[index][\"filename\"]\n            score=self.index1[index][\"score\"]\n        else:\n            index-=self.len1\n            if (index<len(self.index2)*6):\n                word=self.index2[index//6][\"word\"]\n                filename1=self.path2+self.index1[index//6][\"filename\"]\n                score=self.index2[index//6][\"score\"]\n        item = self.dframe0.loc[self.dframe0['word']==word]\n        fileName = item[\"filename\"].values[0]\n        filename2 = self.path0 + fileName\n        #filename2=self.path0+self.dframe0.loc[self.dframe0[\"word\"]==word][\"filename\"][1]\n        \n        input_one = Image.open(filename2)\n        input_one_np = numpy.array(input_one)\n        input_one=numpy.where(numpy.sum(input_one_np,axis=2)==3*255,0,1)\n        # print(input_one.shape)\n\n        input_two = Image.open(filename1)\n        input_two_np = numpy.array(input_two)\n        input_two=numpy.where(input_two_np==255,0,1)\n        # print(input_two.shape)\n        \n        \n        input_one_tensor = torch.tensor(input_one, dtype=torch.float32).unsqueeze(0)\n        input_two_tensor = torch.tensor(input_two, dtype=torch.float32).unsqueeze(0)\n        label_tensor = torch.tensor(int(score),dtype=torch.float32)\n        # input_one.cuda()\n        # input_two.cuda()\n        # label.cuda()\n        input_one_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_one_tensor)\n        input_two_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_two_tensor)\n        return input_one_tensor,input_two_tensor, label_tensor\n\n    def __len__(self):\n#         len_1=len(self.index1)//4\n#         len_1=0\n#         len_2=len(self.index2)*6\n        return self.len1+self.len2\n\ndataset = CustomDataset(path=\"E:/MyProject/\")\nprint(len(dataset))\ndataloader=data.DataLoader(\n    dataset,\n    batch_size=1,\n    #num_worders=8,\n    shuffle=True,\n    pin_memory=True\n)\n\n# net\n\nsiamese=torch.load(\"./model.pth\").cpu()\nprint (len(dataset))\naccuracy=0\nfor i,(image1,image2,labels) in enumerate(test_dataloader):\n    \n    outputs=siamese(image1,image2)\n    pred=outputs\n\n    labels=labels.cpu().numpy()[0]\n    pred=pred.cpu().detach().numpy()[0]\n    # batchsize*1*28*28\n    # 通道数（灰度图=1） 在显示时应放在最后\n\n    print(\"label\",labels)\n    print(\"pred\",pred)\n\naccuracy=torch.sqrt(accuracy/len(dataset))\n# 方差\nprint(\"accuracy is {}\".format(accuracy))\n      ","metadata":{},"execution_count":null,"outputs":[]}]}