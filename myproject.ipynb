{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"include","metadata":{}},{"cell_type":"code","source":"# -*- encoding: utf-8 -*-\n# siemese.py\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nfrom torch.utils import data\nimport cv2\nimport json\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy\nfrom PIL import Image\nimport pandas as pd\nfrom ast import Add\nfrom logging import critical\nfrom multiprocessing import reduction\nfrom turtle import forward\n\n#from siamese_net import SiameseNetwork\n#from CustomDataset import CustomDataset\n","metadata":{"execution":{"iopub.status.busy":"2022-10-30T07:20:58.078192Z","iopub.execute_input":"2022-10-30T07:20:58.078594Z","iopub.status.idle":"2022-10-30T07:20:58.370781Z","shell.execute_reply.started":"2022-10-30T07:20:58.078555Z","shell.execute_reply":"2022-10-30T07:20:58.369647Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.copy(\"../input/myproject-model/model (6).pth\",\"./model.pth\")","metadata":{"execution":{"iopub.status.busy":"2022-10-30T04:39:17.802948Z","iopub.execute_input":"2022-10-30T04:39:17.803538Z","iopub.status.idle":"2022-10-30T04:39:19.306552Z","shell.execute_reply.started":"2022-10-30T04:39:17.803497Z","shell.execute_reply":"2022-10-30T04:39:19.304968Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'./model.pth'"},"metadata":{}}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('model.pth')","metadata":{"execution":{"iopub.status.busy":"2022-10-29T12:14:32.708194Z","iopub.execute_input":"2022-10-29T12:14:32.708504Z","iopub.status.idle":"2022-10-29T12:14:32.717727Z","shell.execute_reply.started":"2022-10-29T12:14:32.708480Z","shell.execute_reply":"2022-10-29T12:14:32.716709Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/model.pth","text/html":"<a href='model.pth' target='_blank'>model.pth</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"#callbacks.py\nclass LossHistory():\n    def __init__(self, log_dir, model, input_shape):\n        time_str        = datetime.datetime.strftime(datetime.datetime.now(),'%Y_%m_%d_%H_%M_%S')\n        self.log_dir    = os.path.join(log_dir, \"loss_\" + str(time_str))\n        self.losses     = []\n        self.val_loss   = []\n        \n        os.makedirs(self.log_dir)\n        self.writer     = SummaryWriter(self.log_dir)\n        try:\n            dummy_input     = torch.randn(2, 2, 3, input_shape[0], input_shape[1])\n            self.writer.add_graph(model, dummy_input)\n        except:\n            pass\n\n    def append_loss(self, epoch, loss, val_loss):\n        if not os.path.exists(self.log_dir):\n            os.makedirs(self.log_dir)\n\n        self.losses.append(loss)\n        self.val_loss.append(val_loss)\n\n        with open(os.path.join(self.log_dir, \"epoch_loss.txt\"), 'a') as f:\n            f.write(str(loss))\n            f.write(\"\\n\")\n        with open(os.path.join(self.log_dir, \"epoch_val_loss.txt\"), 'a') as f:\n            f.write(str(val_loss))\n            f.write(\"\\n\")\n\n        self.writer.add_scalar('loss', loss, epoch)\n        self.writer.add_scalar('val_loss', val_loss, epoch)\n        self.loss_plot()\n\n    def loss_plot(self):\n        iters = range(len(self.losses))\n\n        plt.figure()\n        plt.plot(iters, self.losses, 'red', linewidth = 2, label='train loss')\n        plt.plot(iters, self.val_loss, 'coral', linewidth = 2, label='val loss')\n        try:\n            if len(self.losses) < 25:\n                num = 5\n            else:\n                num = 15\n            \n            plt.plot(iters, scipy.signal.savgol_filter(self.losses, num, 3), 'green', linestyle = '--', linewidth = 2, label='smooth train loss')\n            plt.plot(iters, scipy.signal.savgol_filter(self.val_loss, num, 3), '#8B4513', linestyle = '--', linewidth = 2, label='smooth val loss')\n        except:\n            pass\n\n        plt.grid(True)\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss')\n        plt.legend(loc=\"upper right\")\n\n        plt.savefig(os.path.join(self.log_dir, \"epoch_loss.png\"))\n\n        plt.cla()\n        plt.close(\"all\")","metadata":{"execution":{"iopub.status.busy":"2022-10-29T16:43:11.135551Z","iopub.execute_input":"2022-10-29T16:43:11.135890Z","iopub.status.idle":"2022-10-29T16:43:11.179856Z","shell.execute_reply.started":"2022-10-29T16:43:11.135812Z","shell.execute_reply":"2022-10-29T16:43:11.178113Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"训练网络","metadata":{}},{"cell_type":"code","source":"# all\naverage=torch.tensor(80.6786)\nvariance=torch.tensor(9.0062)\nclass SiameseNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.cnn1 = nn.Sequential(\n            nn.BatchNorm2d(1,affine=True), # B*C*H*W\n            nn.Conv2d(1, 64, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 64 * 32 * 32\n        )\n        self.cnn2 = nn.Sequential(\n            nn.BatchNorm2d(64,affine=True), # B*C*H*W\n            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            # nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            # nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 128 * 16 * 16\n        )\n        self.cnn3 = nn.Sequential(\n            nn.BatchNorm2d(128,affine=True), # B*C*H*W\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            # nn.ReLU(inplace=True),\n            # nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 256 * 8 * 8\n        )\n        self.cnn4 = nn.Sequential(\n            nn.BatchNorm2d(256,affine=True), # B*C*H*W\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2),\n            # B * 512 * 4 * 4\n        )\n\n        self.fc1 = nn.Sequential(\n#             nn.Linear(512 * 4 * 4, 100, bias=True),\n            nn.Linear(256*8*8,1024,bias=True),\n#             nn.Linear(1000, 100, bias=True),\n            nn.ReLU(inplace=True),\n            nn.Linear(1024,1024,bias=True),\n            # nn.Linear(20, 1)\n        )\n\n        self.fc2 = nn.Sequential(\n#             nn.Linear(100, 20),\n#             nn.ReLU(inplace=True),\n#             nn.Linear(20,1),\n            nn.Linear(1024,100),\n            nn.ReLU(inplace=True),\n            nn.Linear(100,1),\n        )\n        # for m in self.modules():\n        #     if isinstance(m,nn.Conv2d):\n        #         nn.init.kaiming_normal_(m.weight.data,0.3)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0.3)\n        #     elif isinstance(m,nn.Linear):\n        #         nn.init.kaiming_normal_(m.weight.data)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0.5)\n        #     elif isinstance(m,nn.BatchNorm2d):\n        #         nn.init.kaiming_normal_(m.weight.data,0.3)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0)\n    def forward_once(self, x):\n        B, C, H, W = x.shape\n        output = self.cnn1(x)\n        output = self.cnn2(output)\n        output = self.cnn3(output)\n#         output = self.cnn4(output)\n#         output = output.view(B, 512*4*4)\n        output=output.view(B,256*8*8)\n        output = self.fc1(output)\n#         output = output.view(B,100)\n#         output = nn.BatchNorm1d(100,eps=1e-4,affine=True).cuda()(output) # B*C*H*W\n#         output = nn.Sigmoid()(output)\n        return output\n\n    def forward(self, input1, input2):\n        B, C, H, W = input1.shape\n        output1 = self.forward_once(input1)\n        # 7*20\n        output2 = self.forward_once(input2)\n#         output3 = nn.functional.cosine_similarity(output1, output2, dim=1)-torch.ones((1,B)).cuda()*0.995\n#         output3=torch.abs(output2-output1).sum(dim=1)\n#         output3=(output1-output2).norm(2,dim=1,keepdim=True)\n        output3=torch.abs(output1-output2)\n        output3=self.fc2(output3)\n#         output3 = output3.resize(B, 1)\n        output4=output3\n        output4=output4*variance+average\n#         output4=100*(torch.ones(B,1).cuda()-output4)\n        output4=torch.min(output4,torch.ones(B,1).cuda()*100)\n        return output4\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, path):\n        super(CustomDataset,self).__init__()\n        # path=\"E:/MyProject/\"\n        self.path0=\"../input/standard/standard/\"\n        self.path1=\"../input/train1/train1/\"\n        self.path2=\"../input/train2/train2/\"\n        self.index0=json.loads(open(\"../input/index-standard/index_standard.json\",'r',encoding='utf-8').read())\n        self.index1=json.loads(open(\"../input/index-train1/index_train1.json\",'r',encoding='utf-8').read())\n        self.index2=json.loads(open(\"../input/index-train2/index_train2.json\",'r',encoding='utf-8').read())\n        self.dframe0=pd.DataFrame(self.index0)\n#         self.len1=len(self.index1)//4\n        self.len1=0\n        self.len2=len(self.index2)*6\n    def __getitem__(self,index):\n        if (index<self.len1):\n            word=self.index1[index][\"word\"]\n            filename1=self.path1+self.index1[index][\"filename\"]\n            score=self.index1[index][\"score\"]\n        else:\n            index-=self.len1\n            if (index<len(self.index2)*6):\n                word=self.index2[index//6][\"word\"]\n                filename1=self.path2+self.index1[index//6][\"filename\"]\n                score=self.index2[index//6][\"score\"]\n        item = self.dframe0.loc[self.dframe0['word']==word]\n        fileName = item[\"filename\"].values[0]\n        filename2 = self.path0 + fileName\n        #filename2=self.path0+self.dframe0.loc[self.dframe0[\"word\"]==word][\"filename\"][1]\n        \n        input_one = Image.open(filename2)\n        input_one_np = numpy.array(input_one)\n        input_one=numpy.where(numpy.sum(input_one_np,axis=2)==3*255,0,1)\n        # print(input_one.shape)\n\n        input_two = Image.open(filename1)\n        input_two_np = numpy.array(input_two)\n        input_two=numpy.where(input_two_np==255,0,1)\n        # print(input_two.shape)\n        \n        \n        input_one_tensor = torch.tensor(input_one, dtype=torch.float32).unsqueeze(0)\n        input_two_tensor = torch.tensor(input_two, dtype=torch.float32).unsqueeze(0)\n        label_tensor = torch.tensor(int(score),dtype=torch.float32)\n        # input_one.cuda()\n        # input_two.cuda()\n        # label.cuda()\n        input_one_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_one_tensor)\n        input_two_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_two_tensor)\n        return input_one_tensor,input_two_tensor, label_tensor\n\n    def __len__(self):\n#         len_1=len(self.index1)//4\n#         len_1=0\n#         len_2=len(self.index2)*6\n        return self.len1+self.len2\n\n# train.py\ndataset = CustomDataset(path=\"E:/MyProject/\")\nprint(len(dataset))\n#train_dataset,test_dataset=data.random_split(dataset,torch(len(dataset)/100*95),len(dataset)-torch.floor(len(dataset)/100*95))\nn_train = int(len(dataset)/100*95)\nn_val = len(dataset) - n_train\ntrain_dataset,test_dataset=data.random_split(dataset,[n_train, n_val])\nprint(len(train_dataset))\nprint(len(test_dataset))\ntrain_dataloader=data.DataLoader(\n    train_dataset,\n    batch_size=64,    \n    shuffle=True,\n    #num_worders=8,\n    pin_memory=True,\n    drop_last=True\n)\ntest_dataloader=data.DataLoader(\n    test_dataset,\n    batch_size=1,\n    #num_worders=8,\n    shuffle=True,\n    pin_memory=True\n)\n\n\n# net\n\nsiamese=torch.load(\"./model.pth\")\n# siamese=SiameseNetwork()\nsiamese=siamese.cuda()\n#siamese =SiameseNetwork().cuda() #定义模型以致GPU\n\n# loss\n# loss_func = ContrastiveLoss() #定义损失函数\nloss_func = torch.nn.MSELoss()\n#----------------------#\n#   获得损失函数\n#----------------------#\n#loss_func = torch.nn.BCEWithLogitsLoss()\n#----------------------#\n#   记录Loss\n#----------------------#\n# if local_rank == 0:\n#     loss_history = LossHistory(save_dir, model, input_shape=input_shape)\n# else:\n#     loss_history = None\n\naverage=torch.tensor(83.0401)\nvariance=torch.tensor(10.2655)\n\ntrain_list=[siamese.cnn1,siamese.cnn2,siamese.cnn3,siamese.fc1,siamese.fc2]\ndef train(a,b):\n    params=[\n        {\"params\":siamese.cnn1.parameters(),\"lr\":a},\n        {\"params\":siamese.cnn2.parameters(),\"lr\":a},\n        {\"params\":siamese.cnn3.parameters(),\"lr\":a},\n        {\"params\":siamese.cnn4.parameters(),\"lr\":a},\n        {\"params\":siamese.fc1.parameters(),\"lr\":b},\n        {\"params\":siamese.fc2.parameters(),\"lr\":b},\n    ]\n    optimizer=torch.optim.Adam(params) # Adam对学习率不太敏感\n    lost_sum=0\n    for i, (image1,image2,labels) in enumerate(train_dataloader): # enumerate 将一个可遍历的数据对象组合为一个索引序列\n        image1=image1.cuda()\n        image2=image2.cuda()\n        \n        labels=labels.cuda()\n#         print(image1.shape)\n#         print(image2.shape)\n        \n        # print(image1.shape, image2.shape)\n        optimizer.zero_grad()\n        outputs=siamese(image1,image2)\n        # print(outputs.shape, labels.shape)\n        loss=loss_func(outputs,labels)\n        lost_sum=lost_sum+((outputs-labels)*(outputs-labels)).sum()\n        loss.backward()\n        optimizer.step()\n#         print(\"epoch is {}, ite is {}/{}, loss is {}\".format(epoch+1, i, len(train_dataset) // 64, loss.item()))\n    torch.save(siamese,\"./model.pth\")\n    lost_sum=lost_sum/len(train_dataset)\n    print(lost_sum.sqrt())\n# training\n\nfor epoch in range(50): #epoch one usage of whole dataset\n    train(1e-5,1e-5)\n    train(1e-5,0)\n    train(0,1e-5)\n        \n    loss_test=0\n    lst=[]\n    for i,(image1,image2,labels) in enumerate(test_dataloader):\n        image1=image1.cuda()\n        image2=image2.cuda()\n        outputs=siamese(image1,image2)\n        outputs=outputs.cpu()\n        labels=labels.to(torch.float32)\n        #[batchsize]\n        #outputs=batchsize*cls_num\n        now=(outputs-labels)*(outputs-labels)\n        lst.append(outputs)\n        loss_test += now\n        if (i % 40 ==0):\n            print(outputs,labels)\n        # _, pred=outputs.max(dim=1)\n    loss_test=torch.sqrt(loss_test/len(test_dataloader))\n    print(\"epoch is {}, loss test is {}\".format(epoch+1,loss_test.item()))\n    \n    lst=torch.tensor(lst)\n    print(\"mean={},std={}\".format(torch.mean(lst),torch.std(lst)))\n    # input(\"next\")\n\ntorch.save(siamese,\"./model.pth\")\n\n# eval/test\n# save\n\n# load\n# inference","metadata":{"execution":{"iopub.status.busy":"2022-10-30T04:42:10.475806Z","iopub.execute_input":"2022-10-30T04:42:10.476302Z","iopub.status.idle":"2022-10-30T05:39:45.385005Z","shell.execute_reply.started":"2022-10-30T04:42:10.476263Z","shell.execute_reply":"2022-10-30T05:39:45.383062Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"7038\n6686\n352\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n","output_type":"stream"},{"name":"stdout","text":"tensor(72.0779, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0335, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0603, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[80.7151]], grad_fn=<ToCopyBackward0>) tensor([83.])\ntensor([[80.5497]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[80.6833]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[80.5771]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[80.5092]], grad_fn=<ToCopyBackward0>) tensor([63.])\ntensor([[80.7235]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[80.5851]], grad_fn=<ToCopyBackward0>) tensor([79.])\ntensor([[80.4518]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[80.8379]], grad_fn=<ToCopyBackward0>) tensor([93.])\nepoch is 1, loss test is 8.5984525680542\nmean=80.70970916748047,std=0.1797911822795868\ntensor(72.0507, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0672, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0204, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[80.6340]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[80.7547]], grad_fn=<ToCopyBackward0>) tensor([81.])\ntensor([[80.5416]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[80.4242]], grad_fn=<ToCopyBackward0>) tensor([65.])\ntensor([[80.2963]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[80.6717]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[80.2705]], grad_fn=<ToCopyBackward0>) tensor([71.])\ntensor([[80.8486]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[80.3391]], grad_fn=<ToCopyBackward0>) tensor([55.])\nepoch is 2, loss test is 8.607152938842773\nmean=80.65662384033203,std=0.1804032027721405\ntensor(71.9906, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.1263, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0868, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[80.5938]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[80.6323]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[80.6752]], grad_fn=<ToCopyBackward0>) tensor([75.])\ntensor([[80.9085]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[80.7653]], grad_fn=<ToCopyBackward0>) tensor([81.])\ntensor([[80.6130]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[81.2264]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[80.6396]], grad_fn=<ToCopyBackward0>) tensor([63.])\ntensor([[80.5538]], grad_fn=<ToCopyBackward0>) tensor([92.])\nepoch is 3, loss test is 8.597286224365234\nmean=80.70453643798828,std=0.16662836074829102\ntensor(72.1014, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0012, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0520, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[80.8278]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[80.6796]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[80.6946]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[80.9950]], grad_fn=<ToCopyBackward0>) tensor([60.])\ntensor([[80.7150]], grad_fn=<ToCopyBackward0>) tensor([81.])\ntensor([[80.5551]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[80.5106]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[80.8106]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[80.8099]], grad_fn=<ToCopyBackward0>) tensor([70.])\nepoch is 4, loss test is 8.612171173095703\nmean=80.73760223388672,std=0.16713450849056244\ntensor(72.0111, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0257, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.1143, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[80.8048]], grad_fn=<ToCopyBackward0>) tensor([73.])\ntensor([[80.7673]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[80.8066]], grad_fn=<ToCopyBackward0>) tensor([79.])\ntensor([[80.6000]], grad_fn=<ToCopyBackward0>) tensor([72.])\ntensor([[80.9824]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[81.1431]], grad_fn=<ToCopyBackward0>) tensor([83.])\ntensor([[80.6647]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[80.9251]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[80.6340]], grad_fn=<ToCopyBackward0>) tensor([83.])\nepoch is 5, loss test is 8.6021146774292\nmean=80.73104858398438,std=0.17233780026435852\ntensor(72.0740, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0034, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0691, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[80.9705]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[80.5223]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[80.8526]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[80.5662]], grad_fn=<ToCopyBackward0>) tensor([79.])\ntensor([[80.4816]], grad_fn=<ToCopyBackward0>) tensor([83.])\ntensor([[80.4784]], grad_fn=<ToCopyBackward0>) tensor([72.])\ntensor([[80.7855]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[80.5098]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[80.8181]], grad_fn=<ToCopyBackward0>) tensor([74.])\nepoch is 6, loss test is 8.604508399963379\nmean=80.6727294921875,std=0.16615000367164612\ntensor(71.9908, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0891, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0292, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[80.4615]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[80.7132]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[80.6291]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[80.4859]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[80.7668]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[80.7943]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[80.6801]], grad_fn=<ToCopyBackward0>) tensor([83.])\ntensor([[80.8074]], grad_fn=<ToCopyBackward0>) tensor([82.])\ntensor([[80.5838]], grad_fn=<ToCopyBackward0>) tensor([90.])\nepoch is 7, loss test is 8.59869384765625\nmean=80.71495819091797,std=0.16357144713401794\ntensor(72.0835, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0205, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0658, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[80.5948]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[80.7516]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[80.8358]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[80.6769]], grad_fn=<ToCopyBackward0>) tensor([73.])\ntensor([[80.8037]], grad_fn=<ToCopyBackward0>) tensor([82.])\ntensor([[80.6533]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[80.2691]], grad_fn=<ToCopyBackward0>) tensor([63.])\ntensor([[80.8240]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[80.8169]], grad_fn=<ToCopyBackward0>) tensor([87.])\nepoch is 8, loss test is 8.602758407592773\nmean=80.7129898071289,std=0.16682970523834229\ntensor(72.0490, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0118, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0846, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[80.9281]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[80.9738]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[80.6141]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[80.5490]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[80.8297]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[80.9135]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[80.8221]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[80.8302]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[80.7578]], grad_fn=<ToCopyBackward0>) tensor([92.])\nepoch is 9, loss test is 8.597052574157715\nmean=80.6828384399414,std=0.1765403151512146\ntensor(72.0893, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0110, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0354, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[80.4407]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[80.8106]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[80.3471]], grad_fn=<ToCopyBackward0>) tensor([64.])\ntensor([[80.4015]], grad_fn=<ToCopyBackward0>) tensor([55.])\ntensor([[80.7611]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[80.6564]], grad_fn=<ToCopyBackward0>) tensor([67.])\ntensor([[80.7504]], grad_fn=<ToCopyBackward0>) tensor([83.])\ntensor([[80.7402]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[80.7704]], grad_fn=<ToCopyBackward0>) tensor([62.])\nepoch is 10, loss test is 8.606383323669434\nmean=80.67686462402344,std=0.1703464239835739\ntensor(72.0828, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0259, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0734, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[80.7278]], grad_fn=<ToCopyBackward0>) tensor([75.])\ntensor([[81.1127]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[80.6176]], grad_fn=<ToCopyBackward0>) tensor([75.])\ntensor([[80.5905]], grad_fn=<ToCopyBackward0>) tensor([72.])\ntensor([[80.4960]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[80.6167]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[80.9045]], grad_fn=<ToCopyBackward0>) tensor([82.])\ntensor([[80.4775]], grad_fn=<ToCopyBackward0>) tensor([82.])\ntensor([[80.4655]], grad_fn=<ToCopyBackward0>) tensor([86.])\nepoch is 11, loss test is 8.607681274414062\nmean=80.67211151123047,std=0.17606070637702942\ntensor(72.0686, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(71.9976, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0741, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[80.2761]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[80.7537]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[80.6048]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[80.8313]], grad_fn=<ToCopyBackward0>) tensor([83.])\ntensor([[80.5751]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[80.8217]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[80.5951]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[81.0930]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[80.5460]], grad_fn=<ToCopyBackward0>) tensor([72.])\nepoch is 12, loss test is 8.608837127685547\nmean=80.67005920410156,std=0.17019426822662354\ntensor(72.0132, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0992, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0519, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[80.8917]], grad_fn=<ToCopyBackward0>) tensor([94.])\ntensor([[81.0402]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[80.6741]], grad_fn=<ToCopyBackward0>) tensor([82.])\ntensor([[80.6963]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[80.8802]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[80.5619]], grad_fn=<ToCopyBackward0>) tensor([65.])\ntensor([[80.6879]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[80.7526]], grad_fn=<ToCopyBackward0>) tensor([68.])\ntensor([[80.6210]], grad_fn=<ToCopyBackward0>) tensor([83.])\nepoch is 13, loss test is 8.6058931350708\nmean=80.68429565429688,std=0.1770423799753189\ntensor(72.0492, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0195, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0228, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[80.5594]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[80.6600]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[80.7519]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[80.8067]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[80.5749]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[80.7078]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[80.6245]], grad_fn=<ToCopyBackward0>) tensor([74.])\ntensor([[80.7504]], grad_fn=<ToCopyBackward0>) tensor([79.])\ntensor([[80.7899]], grad_fn=<ToCopyBackward0>) tensor([88.])\nepoch is 14, loss test is 8.602436065673828\nmean=80.71443176269531,std=0.16629540920257568\ntensor(72.0411, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0858, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0021, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[80.5536]], grad_fn=<ToCopyBackward0>) tensor([72.])\ntensor([[80.8830]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[80.3431]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[80.8018]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[80.5172]], grad_fn=<ToCopyBackward0>) tensor([55.])\ntensor([[80.7470]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[80.7302]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[80.7393]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[81.1225]], grad_fn=<ToCopyBackward0>) tensor([84.])\nepoch is 15, loss test is 8.600565910339355\nmean=80.71536254882812,std=0.16710074245929718\ntensor(72.0170, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0577, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0960, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[80.5425]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[80.6145]], grad_fn=<ToCopyBackward0>) tensor([81.])\ntensor([[80.7509]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[80.9973]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[80.6801]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[80.9332]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[80.7239]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[81.0267]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[80.6696]], grad_fn=<ToCopyBackward0>) tensor([72.])\nepoch is 16, loss test is 8.606118202209473\nmean=80.68999481201172,std=0.16538357734680176\ntensor(72.0274, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0474, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.1237, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[80.7477]], grad_fn=<ToCopyBackward0>) tensor([75.])\ntensor([[80.7493]], grad_fn=<ToCopyBackward0>) tensor([92.])\ntensor([[80.6462]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[80.7004]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[80.8121]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[80.8605]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[80.4564]], grad_fn=<ToCopyBackward0>) tensor([83.])\ntensor([[80.6863]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[80.4565]], grad_fn=<ToCopyBackward0>) tensor([70.])\nepoch is 17, loss test is 8.600122451782227\nmean=80.70143127441406,std=0.1767270416021347\ntensor(71.9384, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0887, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0946, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[80.6416]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[80.4804]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[80.9161]], grad_fn=<ToCopyBackward0>) tensor([83.])\ntensor([[80.3881]], grad_fn=<ToCopyBackward0>) tensor([79.])\ntensor([[80.9050]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[80.8608]], grad_fn=<ToCopyBackward0>) tensor([71.])\ntensor([[80.7305]], grad_fn=<ToCopyBackward0>) tensor([73.])\ntensor([[80.9450]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[80.4819]], grad_fn=<ToCopyBackward0>) tensor([86.])\nepoch is 18, loss test is 8.595052719116211\nmean=80.70057678222656,std=0.17182663083076477\ntensor(71.9733, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0317, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.1151, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[80.5262]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[80.7138]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[80.5270]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[80.3838]], grad_fn=<ToCopyBackward0>) tensor([71.])\ntensor([[80.5530]], grad_fn=<ToCopyBackward0>) tensor([72.])\ntensor([[80.3183]], grad_fn=<ToCopyBackward0>) tensor([63.])\ntensor([[81.0871]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[80.4435]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[80.7781]], grad_fn=<ToCopyBackward0>) tensor([84.])\nepoch is 19, loss test is 8.598188400268555\nmean=80.67011260986328,std=0.18549591302871704\ntensor(72.0744, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0674, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0121, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[80.6101]], grad_fn=<ToCopyBackward0>) tensor([65.])\ntensor([[80.7435]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[80.5142]], grad_fn=<ToCopyBackward0>) tensor([72.])\ntensor([[81.0252]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[81.0996]], grad_fn=<ToCopyBackward0>) tensor([94.])\ntensor([[80.7777]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[80.9202]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[80.7343]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[80.7146]], grad_fn=<ToCopyBackward0>) tensor([76.])\nepoch is 20, loss test is 8.59986686706543\nmean=80.73063659667969,std=0.16482777893543243\ntensor(72.0840, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.1066, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0287, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[80.5108]], grad_fn=<ToCopyBackward0>) tensor([85.])\ntensor([[80.6195]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[80.5342]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[80.6702]], grad_fn=<ToCopyBackward0>) tensor([60.])\ntensor([[80.7667]], grad_fn=<ToCopyBackward0>) tensor([93.])\ntensor([[80.7438]], grad_fn=<ToCopyBackward0>) tensor([73.])\ntensor([[80.7137]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[80.5566]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[80.6403]], grad_fn=<ToCopyBackward0>) tensor([90.])\nepoch is 21, loss test is 8.605362892150879\nmean=80.67534637451172,std=0.16897794604301453\ntensor(72.0155, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor(72.0905, device='cuda:0', grad_fn=<SqrtBackward0>)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/812731340.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0mloss_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_17/812731340.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Adam对学习率不太敏感\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mlost_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# enumerate 将一个可遍历的数据对象组合为一个索引序列\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0mimage1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mimage2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_17/812731340.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mfilename1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"filename\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdframe0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdframe0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0mfileName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"filename\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mfilename2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfileName\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__eq__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__ne__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5501\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5502\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5504\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"使用普通的VGG网络，效果一般","metadata":{}},{"cell_type":"markdown","source":"预训练res18","metadata":{}},{"cell_type":"code","source":"# -*- encoding: utf-8 -*-\n# resnet18\n# siemese.py\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nfrom torch.utils import data\nimport cv2\nimport json\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy\nfrom PIL import Image\nimport pandas as pd\nfrom ast import Add\nfrom logging import critical\nfrom multiprocessing import reduction\n\n\n#from siamese_net import SiameseNetwork\n#from CustomDataset import CustomDataset\nfrom urllib.request import urlopen\nfrom torchvision.models import resnet18\naverage=torch.tensor(80.6786)\nvariance=torch.tensor(9.0062)\nclass SiameseNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        basenet=resnet18(pretrained=True)\n        self.conv_5=nn.Sequential(\n            nn.Sequential(\n                basenet.conv1,\n                basenet.bn1,\n                basenet.relu,\n                basenet.maxpool\n            ),\n            basenet.layer1,\n            basenet.layer1,\n            basenet.layer1,\n            basenet.layer1,\n        )\n#         self.stage0=nn.Sequential(\n#             basenet.conv1,\n#             basenet.bn1,\n#             basenet.relu,\n#             basenet.maxpool\n#         )\n#         self.stage1=basenet.layer1\n#         self.stage2=basenet.layer1\n#         self.stage3=basenet.layer1\n#         self.stage4=basenet.layer1\n        \n        self.fc1 = nn.Sequential(\n            nn.Linear(16*16*64,256,bias=True),\n            nn.ReLU(inplace=True),\n            # nn.Linear(20, 1)\n        )\n\n        self.fc2 = nn.Sequential(\n#             nn.Linear(100, 20),\n#             nn.ReLU(inplace=True),\n#             nn.Linear(20,1),\n            nn.Linear(512,100),\n            nn.ReLU(inplace=True),\n            nn.Linear(100,1),\n            nn.Sigmoid(),\n        )\n    def forward_once(self, x):\n        B, C, H, W = x.shape\n        x=torch.cat([x,x,x],dim=1)\n        f=self.conv_5(x)\n#         print(f.shape)\n        output=f.view(B,16*16*64)\n        output = self.fc1(output)\n#         output = output.view(B,100)\n#         output = nn.BatchNorm1d(100,eps=1e-4,affine=True).cuda()(output) # B*C*H*W\n#         output = nn.Sigmoid()(output)\n        return output\n\n    def forward(self, input1, input2):\n        B, C, H, W = input1.shape\n        output1 = self.forward_once(input1)\n        # 7*20\n        output2 = self.forward_once(input2)\n        output3=torch.cat([output1,output2],dim=1)\n        output3=self.fc2(output3)\n#         output3 = output3.resize(B, 1)\n        output4=output3\n        output4=output4*100\n#         output4=output4*variance+average\n#         output4=100*(torch.ones(B,1).cuda()-output4)\n#         output4=torch.min(output4,torch.ones(B,1).cuda()*100)\n        return output4\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, path):\n        super(CustomDataset,self).__init__()\n        # path=\"E:/MyProject/\"\n        self.path0=\"../input/standard/standard/\"\n        self.path1=\"../input/train1/train1/\"\n        self.path2=\"../input/train2/train2/\"\n        self.index0=json.loads(open(\"../input/index-standard/index_standard.json\",'r',encoding='utf-8').read())\n        self.index1=json.loads(open(\"../input/index-train1/index_train1.json\",'r',encoding='utf-8').read())\n        self.index2=json.loads(open(\"../input/index-train2/index_train2.json\",'r',encoding='utf-8').read())\n        self.dframe0=pd.DataFrame(self.index0)\n#         self.len1=len(self.index1)//4\n        self.len1=0\n        self.len2=len(self.index2)*6\n    def __getitem__(self,index):\n        if (index<self.len1):\n            word=self.index1[index][\"word\"]\n            filename1=self.path1+self.index1[index][\"filename\"]\n            score=self.index1[index][\"score\"]\n        else:\n            index-=self.len1\n            if (index<len(self.index2)*6):\n                word=self.index2[index//6][\"word\"]\n                filename1=self.path2+self.index1[index//6][\"filename\"]\n                score=self.index2[index//6][\"score\"]\n        item = self.dframe0.loc[self.dframe0['word']==word]\n        fileName = item[\"filename\"].values[0]\n        filename2 = self.path0 + fileName\n        #filename2=self.path0+self.dframe0.loc[self.dframe0[\"word\"]==word][\"filename\"][1]\n        \n        input_one = Image.open(filename2)\n        input_one_np = numpy.array(input_one)\n        input_one=numpy.where(numpy.sum(input_one_np,axis=2)==3*255,0,1)\n        # print(input_one.shape)\n\n        input_two = Image.open(filename1)\n        input_two_np = numpy.array(input_two)\n        input_two=numpy.where(input_two_np==255,0,1)\n        # print(input_two.shape)\n        \n        \n        input_one_tensor = torch.tensor(input_one, dtype=torch.float32).unsqueeze(0)\n        input_two_tensor = torch.tensor(input_two, dtype=torch.float32).unsqueeze(0)\n        label_tensor = torch.tensor(int(score),dtype=torch.float32)\n        # input_one.cuda()\n        # input_two.cuda()\n        # label.cuda()\n        input_one_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_one_tensor)\n        input_two_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_two_tensor)\n        return input_one_tensor,input_two_tensor, label_tensor\n\n    def __len__(self):\n#         len_1=len(self.index1)//4\n#         len_1=0\n#         len_2=len(self.index2)*6\n        return self.len1+self.len2\n\n# train.py\ndataset = CustomDataset(path=\"E:/MyProject/\")\nprint(len(dataset))\n#train_dataset,test_dataset=data.random_split(dataset,torch(len(dataset)/100*95),len(dataset)-torch.floor(len(dataset)/100*95))\nn_train = int(len(dataset)/100*95)\nn_val = len(dataset) - n_train\ntrain_dataset,test_dataset=data.random_split(dataset,[n_train, n_val])\nprint(len(train_dataset))\nprint(len(test_dataset))\ntrain_dataloader=data.DataLoader(\n    train_dataset,\n    batch_size=64,    \n    shuffle=True,\n    #num_worders=8,\n    pin_memory=True,\n    drop_last=True\n)\ntest_dataloader=data.DataLoader(\n    test_dataset,\n    batch_size=1,\n    #num_worders=8,\n    shuffle=True,\n    pin_memory=True\n)\n\n\n# net\n\ntry:\n    siamese=torch.load(\"./model_res18.pth\")\nexcept:\n    siamese=SiameseNetwork()\nsiamese=siamese.cuda()\n#siamese =SiameseNetwork().cuda() #定义模型以致GPU\n\n# loss\nloss_func = torch.nn.MSELoss()\n\naverage=torch.tensor(83.0401)\nvariance=torch.tensor(10.2655)\n\ndef train(a,b):\n    params=[\n        {\"params\":siamese.conv_5.parameters(),\"lr\":a},\n        {\"params\":siamese.fc1.parameters(),\"lr\":b},\n        {\"params\":siamese.fc2.parameters(),\"lr\":b},\n    ]\n    optimizer=torch.optim.Adam(params) # Adam对学习率不太敏感\n    lost_sum=0\n    for i, (image1,image2,labels) in enumerate(train_dataloader): # enumerate 将一个可遍历的数据对象组合为一个索引序列\n        image1=image1.cuda()\n        image2=image2.cuda()\n        \n        labels=labels.cuda()\n#         print(image1.shape)\n#         print(image2.shape)\n        \n        # print(image1.shape, image2.shape)\n        optimizer.zero_grad()\n        outputs=siamese(image1,image2)\n        # print(outputs.shape, labels.shape)\n        loss=loss_func(outputs,labels)\n        lost_sum=lost_sum+((outputs-labels)*(outputs-labels)).sum()\n        loss.backward()\n        optimizer.step()\n#         print(\"epoch is {}, ite is {}/{}, loss is {}\".format(epoch+1, i, len(train_dataset) // 64, loss.item()))\n    torch.save(siamese,\"./model_res18.pth\")\n    lost_sum=lost_sum/len(train_dataset)\n    print(lost_sum.sqrt())\n# training\n\nfor epoch in range(10): #epoch one usage of whole dataset\n#     train(1e-5,1e-5)\n#     train(1e-5,0)\n#     train(0,1e-5)\n    train(1e-5,1e-3)\n        \n    loss_test=0\n    lst=[]\n    for i,(image1,image2,labels) in enumerate(test_dataloader):\n        image1=image1.cuda()\n        image2=image2.cuda()\n        outputs=siamese(image1,image2)\n        outputs=outputs.cpu()\n        labels=labels.to(torch.float32)\n        #[batchsize]\n        #outputs=batchsize*cls_num\n        now=(outputs-labels)*(outputs-labels)\n        lst.append(outputs)\n        loss_test += now\n        if (i % 40 ==0):\n            print(outputs,labels)\n        # _, pred=outputs.max(dim=1)\n    loss_test=torch.sqrt(loss_test/len(test_dataloader))\n    print(\"epoch is {}, loss test is {}\".format(epoch+1,loss_test.item()))\n    \n    lst=torch.tensor(lst)\n    print(\"mean={},std={}\".format(torch.mean(lst),torch.std(lst)))\n    # input(\"next\")\n\ntorch.save(siamese,\"./model_res18.pth\")\n\n# eval/test\n# save\n\n# load\n# inference","metadata":{"execution":{"iopub.status.busy":"2022-10-30T07:44:17.393779Z","iopub.execute_input":"2022-10-30T07:44:17.394140Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"7038\n6686\n352\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/44.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ebace93120b408893d0c9e16b1834ac"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n","output_type":"stream"},{"name":"stdout","text":"tensor(170.6405, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([74.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([79.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([86.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([89.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([76.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([60.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([88.])\nepoch is 1, loss test is 22.097858428955078\nmean=100.0,std=0.0\ntensor(169.7705, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([65.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([60.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([90.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([82.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([80.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([65.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([79.])\nepoch is 2, loss test is 22.097858428955078\nmean=100.0,std=0.0\ntensor(169.8335, device='cuda:0', grad_fn=<SqrtBackward0>)\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([70.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([64.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([88.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([78.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([84.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([71.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([87.])\ntensor([[100.]], grad_fn=<ToCopyBackward0>) tensor([65.])\nepoch is 3, loss test is 22.097858428955078\nmean=100.0,std=0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# 计算平均值，方差\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, path):\n        super(CustomDataset,self).__init__()\n        # path=\"E:/MyProject/\"\n        self.path0=\"../input/standard/standard/\"\n        self.path1=\"../input/train1/train1/\"\n        self.path2=\"../input/train2/train2/\"\n        self.index0=json.loads(open(\"../input/index-standard/index_standard.json\",'r',encoding='utf-8').read())\n        self.index1=json.loads(open(\"../input/index-train1/index_train1.json\",'r',encoding='utf-8').read())\n        self.index2=json.loads(open(\"../input/index-train2/index_train2.json\",'r',encoding='utf-8').read())\n        self.dframe0=pd.DataFrame(self.index0)\n#         self.len1=len(self.index1)//4\n        self.len1=0\n        self.len2=len(self.index2)*6\n    def __getitem__(self,index):\n        if (index<self.len1):\n            word=self.index1[index][\"word\"]\n            filename1=self.path1+self.index1[index][\"filename\"]\n            score=self.index1[index][\"score\"]\n        else:\n            index-=self.len1\n            if (index<len(self.index2)*6):\n                word=self.index2[index//6][\"word\"]\n                filename1=self.path2+self.index1[index//6][\"filename\"]\n                score=self.index2[index//6][\"score\"]\n        item = self.dframe0.loc[self.dframe0['word']==word]\n        fileName = item[\"filename\"].values[0]\n        filename2 = self.path0 + fileName\n        #filename2=self.path0+self.dframe0.loc[self.dframe0[\"word\"]==word][\"filename\"][1]\n        \n        input_one = Image.open(filename2)\n        input_one_np = numpy.array(input_one)\n        input_one=numpy.where(numpy.sum(input_one_np,axis=2)==3*255,0,1)\n        # print(input_one.shape)\n\n        input_two = Image.open(filename1)\n        input_two_np = numpy.array(input_two)\n        input_two=numpy.where(input_two_np==255,0,1)\n        # print(input_two.shape)\n        \n        \n        input_one_tensor = torch.tensor(input_one, dtype=torch.float32).unsqueeze(0)\n        input_two_tensor = torch.tensor(input_two, dtype=torch.float32).unsqueeze(0)\n        label_tensor = torch.tensor(int(score),dtype=torch.float32)\n        # input_one.cuda()\n        # input_two.cuda()\n        # label.cuda()\n        input_one_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_one_tensor)\n        input_two_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_two_tensor)\n        return input_one_tensor,input_two_tensor, label_tensor\n\n    def __len__(self):\n#         len_1=len(self.index1)//4\n#         len_1=0\n#         len_2=len(self.index2)*6\n        return self.len1+self.len2\n\ndataset = CustomDataset(path=\"E:/MyProject/\")\nl=len(dataset)\ncal1=torch.tensor(0)\ncal2=torch.tensor(0)\nfor i in range(l):\n    a,b,c=dataset.__getitem__(i)\n    cal1=cal1+c\naverage=cal1/l\nfor i in range(l):\n    a,b,c=dataset.__getitem__(i)\n    cal2=cal2+(c-average)*(c-average)\ncal2=cal2/l\ncal2=torch.sqrt(cal2)\nprint(average,cal2)","metadata":{"_uuid":"c9b93d6c-1c2e-4b24-be5c-52e07b4952b9","_cell_guid":"f1e51bb1-f642-4050-a1d4-d5d7f8c029a3","jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"average=torch.tensor(83.0401)\nvariance=torch.tensor(10.2655)\nclass SiameseNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.cnn1 = nn.Sequential(\n            nn.BatchNorm2d(1,affine=True), # B*C*H*W\n            nn.Conv2d(1, 64, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 64 * 32 * 32\n        )\n        self.cnn2 = nn.Sequential(\n            nn.BatchNorm2d(64,affine=True), # B*C*H*W\n            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            # nn.Conv2d(128, 128, kernel_size=5, padding=2),\n            # nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 128 * 16 * 16\n        )\n        self.cnn3 = nn.Sequential(\n            nn.BatchNorm2d(128,affine=True), # B*C*H*W\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            # nn.ReLU(inplace=True),\n            # nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 256 * 8 * 8\n        )\n        self.cnn4 = nn.Sequential(\n            nn.BatchNorm2d(256,affine=True), # B*C*H*W\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2)\n            # B * 512 * 4 * 4\n        )\n\n        self.fc1 = nn.Sequential(\n            nn.Linear(512 * 4 * 4, 100, bias=True),\n#             nn.Linear(1000, 100, bias=True),\n            # nn.ReLU(inplace=True),\n            # nn.Linear(20, 1)\n        )\n\n        self.fc2 = nn.Sequential(\n            nn.Linear(100, 1, bias=False),\n        )\n        # for m in self.modules():\n        #     if isinstance(m,nn.Conv2d):\n        #         nn.init.kaiming_normal_(m.weight.data,0.3)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0.3)\n        #     elif isinstance(m,nn.Linear):\n        #         nn.init.kaiming_normal_(m.weight.data)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0.5)\n        #     elif isinstance(m,nn.BatchNorm2d):\n        #         nn.init.kaiming_normal_(m.weight.data,0.3)\n        #         if m.bias is not None:\n        #             nn.init.constant_(m.bias.data,0)\n    def forward_once(self, x):\n        B, C, H, W = x.shape\n        output = self.cnn1(x)\n        output = self.cnn2(output)\n        output = self.cnn3(output)\n        output = self.cnn4(output)\n        output = output.view(B, 512*4*4)\n        output = self.fc1(output)\n#         output = output.view(B,100)\n#         output = nn.BatchNorm1d(100,eps=1e-4,affine=True).cuda()(output) # B*C*H*W\n#         output = nn.Sigmoid()(output)\n        return output\n\n    def forward(self, input1, input2):\n        B, C, H, W = input1.shape\n        output1 = self.forward_once(input1)\n        # 7*20\n        output2 = self.forward_once(input2)\n#         output3 = nn.functional.cosine_similarity(output1, output2, dim=1)-torch.ones((1,B)).cuda()*0.995\n#         output3=torch.abs(output2-output1).sum(dim=1)\n#         output3=(output1-output2).norm(2,dim=1,keepdim=True)\n        output3=output1-output2\n        output3=self.fc2(output3)\n#         output3 = output3.resize(B, 1)\n        output4=output3\n        output4=output4*variance+average\n        return output4\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, path):\n        super(CustomDataset,self).__init__()\n        # path=\"E:/MyProject/\"\n        self.path0=\"../input/standard/standard/\"\n        self.path1=\"../input/train1/train1/\"\n        self.path2=\"../input/train2/train2/\"\n        self.index0=json.loads(open(\"../input/index-standard/index_standard.json\",'r',encoding='utf-8').read())\n        self.index1=json.loads(open(\"../input/index-train1/index_train1.json\",'r',encoding='utf-8').read())\n        self.index2=json.loads(open(\"../input/index-train2/index_train2.json\",'r',encoding='utf-8').read())\n        self.dframe0=pd.DataFrame(self.index0)\n#         self.len1=len(self.index1)//4\n        self.len1=0\n        self.len2=len(self.index2)*6\n    def __getitem__(self,index):\n        if (index<self.len1):\n            word=self.index1[index][\"word\"]\n            filename1=self.path1+self.index1[index][\"filename\"]\n            score=self.index1[index][\"score\"]\n        else:\n            index-=self.len1\n            if (index<len(self.index2)*6):\n                word=self.index2[index//6][\"word\"]\n                filename1=self.path2+self.index1[index//6][\"filename\"]\n                score=self.index2[index//6][\"score\"]\n        item = self.dframe0.loc[self.dframe0['word']==word]\n        fileName = item[\"filename\"].values[0]\n        filename2 = self.path0 + fileName\n        #filename2=self.path0+self.dframe0.loc[self.dframe0[\"word\"]==word][\"filename\"][1]\n        \n        input_one = Image.open(filename2)\n        input_one_np = numpy.array(input_one)\n        input_one=numpy.where(numpy.sum(input_one_np,axis=2)==3*255,0,1)\n        # print(input_one.shape)\n\n        input_two = Image.open(filename1)\n        input_two_np = numpy.array(input_two)\n        input_two=numpy.where(input_two_np==255,0,1)\n        # print(input_two.shape)\n        \n        \n        input_one_tensor = torch.tensor(input_one, dtype=torch.float32).unsqueeze(0)\n        input_two_tensor = torch.tensor(input_two, dtype=torch.float32).unsqueeze(0)\n        label_tensor = torch.tensor(int(score),dtype=torch.float32)\n        # input_one.cuda()\n        # input_two.cuda()\n        # label.cuda()\n        input_one_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_one_tensor)\n        input_two_tensor=transforms.Compose([transforms.RandomAffine(degrees=5,translate=(0.05,0.05)),transforms.ColorJitter(brightness=[0.4,1.0],contrast=[0.7,1.1])])(input_two_tensor)\n        return input_one_tensor,input_two_tensor, label_tensor\n\n    def __len__(self):\n#         len_1=len(self.index1)//4\n#         len_1=0\n#         len_2=len(self.index2)*6\n        return self.len1+self.len2\n\ndataset = CustomDataset(path=\"E:/MyProject/\")\nprint(len(dataset))\ndataloader=data.DataLoader(\n    dataset,\n    batch_size=1,\n    #num_worders=8,\n    shuffle=True,\n    pin_memory=True\n)\n\n# net\n\nsiamese=torch.load(\"./model.pth\").cpu()\nprint (len(dataset))\naccuracy=0\nfor i,(image1,image2,labels) in enumerate(dataloader):\n    \n    outputs=siamese(image1,image2)\n    pred=outputs\n\n    labels=labels.cpu().numpy()[0]\n    pred=pred.cpu().detach().numpy()[0]\n    # batchsize*1*28*28\n    # 通道数（灰度图=1） 在显示时应放在最后\n\n    print(\"label\",labels)\n    print(\"pred\",pred)\n\naccuracy=torch.sqrt(accuracy/len(dataset))\n# 方差\nprint(\"accuracy is {}\".format(accuracy))\n      ","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"运行顺序：shutil-1 -> import -> train/all -> shutil-2\n        shutil-1 -> import -> test -> shutil-2","metadata":{}}]}